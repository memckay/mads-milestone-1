{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silver Data Cleaning\n",
    "\n",
    "**Purpose:** Clean raw data from the [Bronze](./1_bronze.ipynb) layer to create a unified data asset. This includes column standardization, data type enforcement, value harmonization, deduplication, and provenance tracking.\n",
    "\n",
    "**Transformations Applied:**\n",
    "- **Standardize** column names to lowercase snake_case\n",
    "- **Tag** each row with its source region for provenance\n",
    "- **Harmonize** categorical values across data sources\n",
    "- **Enforce** consistent data types\n",
    "\n",
    "This data will be used when creating [Gold](./3_gold.ipynb), where tailored data assets will be created to efficiently answer specific questions.\n",
    "\n",
    "\n",
    "For more on Medallion Architecture, see [Databricks Glossary: Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture) (Databricks, n.d.).\n",
    "\n",
    "---\n",
    "\n",
    "### References  \n",
    "Databricks. (n.d.). *Medallion Architecture*. Retrieved May 10, 2025, from https://www.databricks.com/glossary/medallion-architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup](#setup)  \n",
    "   Install required packages and import libraries.\n",
    "\n",
    "2. [Configuration & Data Loading](#configuration--data-loading)  \n",
    "   Centralize file paths, API parameters, and date-column lists, then ingest the raw Bronze dataset into pandas.\n",
    "\n",
    "3. [Define Helper Functions](#define-helper-functions)  \n",
    "   Define all cleaning and enrichment transforms as modular functions—date anomaly filters, age parsers, imputation routines, etc.\n",
    "\n",
    "4. [Data Cleaning & Standardization](#data-cleaning--standardization)  \n",
    "   Harmonize column names, drop duplicates, and enforce schema across sources.\n",
    "\n",
    "5. [Value Mapping & Data Type Enforcement](#value-mapping--data-type-enforcement)  \n",
    "   Apply categorical/value mappings and cast explicit dtypes for Silver.\n",
    "\n",
    "6. [Execute Transformations](#execute-transformations)  \n",
    "   Run each helper function in sequence to clean and enrich the DataFrame.\n",
    "\n",
    "7. [Create Silver and Exploratory Checks](#create-silver-and-quick-exploratory-checks)  \n",
    "   Inspect missingness, distributions, date ranges, and trends to validate Silver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "**Purpose:**  \n",
    "Ensure the environment has all necessary libraries installed and imported.  \n",
    "```python\n",
    "# Install project-wide dependencies\n",
    "%pip install -r ../../requirements.txt\n",
    "``` \n",
    "\n",
    "> **Note:** we use a project-wide `requirements.txt` for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn==0.13.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 1)) (0.13.2)\n",
      "Requirement already satisfied: pandas==2.2.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib==3.9.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 3)) (3.9.2)\n",
      "Requirement already satisfied: pyarrow==20.0.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 4)) (20.0.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from seaborn==0.13.2->-r ../../requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r ../../requirements.txt (line 2)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 2. Configuration and Data Loading\n",
    "\n",
    "**Purpose:**\n",
    "Here we centralize file paths, API endpoints, and date-column definitions, then ingest every raw Bronze source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source configurations\n",
    "BRONZE_DIR = \"../../data-assets/bronze\"\n",
    "BRONZE_FILE_NAME = \"{}_df.parquet\"\n",
    "\n",
    "# Load all the Bronze datasets\n",
    "BRONZE_FILES = [\"dallas\", \"san_jose\", \"soco\"]\n",
    "BRONZE_FILE_PATHS = {\n",
    "    file: os.path.join(BRONZE_DIR, BRONZE_FILE_NAME.format(file)) for file in BRONZE_FILES \n",
    "}\n",
    "BRONZE_DFS = {\n",
    "    file: pd.read_parquet(path) for file, path in BRONZE_FILE_PATHS.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 3. Define Helper Functions\n",
    "\n",
    "**Purpose:**\n",
    "Below, we define some functions to help us with our transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Data Cleaning ───\n",
    "\n",
    "# Function to apply the column mapping \n",
    "def standardize_columns(source: str, df: pd.DataFrame, mapping: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize DataFrame column names.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The raw DataFrame whose columns need standardization to enable better\n",
    "        analysis.\n",
    "    mapping : dict\n",
    "        A dict where keys are original column names (exact match) and\n",
    "        values are the desired standardized names (snake_case).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A copy of `df` with:\n",
    "        1. Columns renamed according to `mapping`.\n",
    "        2. All column names converted to lowercase.\n",
    "        3. Any duplicate column names (arising when multiple originals map\n",
    "           to the same new name) removed—only the first occurrence is kept.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Columns not present in `mapping` are left unchanged (apart from lowercasing).\n",
    "    - Renaming happens before lowercasing, so mapping keys are case-sensitive.\n",
    "    - Dropping duplicate columns avoids collisions in downstream code.\n",
    "    \"\"\"\n",
    "    # Apply the renaming mapping\n",
    "    df = df.rename(columns=mapping)\n",
    "    # Convert all column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Remove duplicate columns, keeping the first occurrence\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    print(f\" - {source}: {list(df.columns)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_silver_transforms(df: pd.DataFrame, source: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply comprehensive silver-layer transformations to a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame with standardized columns\n",
    "    source : str\n",
    "        Source identifier for provenance tracking\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Transformed DataFrame with harmonized values and proper types\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Add provenance\n",
    "    df['region'] = source\n",
    "    \n",
    "    # Ensure intake_reason column exists\n",
    "    if 'intake_reason' not in df.columns:\n",
    "        df['intake_reason'] = pd.NA\n",
    "    \n",
    "    # Apply data types\n",
    "    for col, dtype in SILVER_DTYPES.items():\n",
    "        if col in df.columns:\n",
    "            if dtype == 'datetime64[ns]':\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            else:\n",
    "                df[col] = df[col].astype(dtype)\n",
    "    \n",
    "    # Data validation: Check for future dates\n",
    "    current_date = pd.Timestamp.now().normalize()\n",
    "    date_columns = ['intake_date', 'outcome_date']\n",
    "    \n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            future_dates = df[col] > current_date\n",
    "            if future_dates.any():\n",
    "                future_count = future_dates.sum()\n",
    "                max_future_date = df.loc[future_dates, col].max()\n",
    "                print(f\"WARNING: Found {future_count:,} future dates in {col} for {source}\")\n",
    "                print(f\"         Latest future date: {max_future_date.date()}\")\n",
    "                print(f\"         Setting future dates to NaT (Not a Time)\")\n",
    "                \n",
    "                # Set future dates to NaT\n",
    "                df.loc[future_dates, col] = pd.NaT\n",
    "    \n",
    "    # Harmonize categorical values\n",
    "    for col, mapping in VALUE_MAPPINGS.items():\n",
    "        if col in df.columns:\n",
    "            # Normalize text before mapping\n",
    "            normalized = df[col].astype(str).str.strip().str.upper()\n",
    "            df[col] = normalized.map(mapping).fillna('other' if col != 'intake_reason' else 'unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_silver_dataset(dataframes: dict[str, pd.DataFrame], schema: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine multiple source DataFrames into unified silver dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframes : dict[str, pd.DataFrame]\n",
    "        Source DataFrames to combine\n",
    "    schema : list[str]\n",
    "        Final column schema to enforce\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Unified silver dataset\n",
    "    \"\"\"\n",
    "    # Combine all sources\n",
    "    combined = pd.concat(dataframes.values(), ignore_index=True, sort=False)\n",
    "    \n",
    "    # Enforce schema\n",
    "    return (\n",
    "        combined\n",
    "        .reindex(columns=schema)\n",
    "        # .drop_duplicates() Dropping duplicates may miss repeat intakes TBD\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_data_overview(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Generate comprehensive data quality overview.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataset to profile\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATA QUALITY PROFILE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Dataset overview\n",
    "    print(f\"\\nDATASET OVERVIEW\")\n",
    "    print(f\"Total records: {df.shape[0]:,}\")\n",
    "    print(f\"Total columns: {df.shape[1]}\")\n",
    "    \n",
    "    # Missing data analysis\n",
    "    print(f\"\\nMISSING DATA ANALYSIS\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_pct = (missing_data / len(df) * 100).round(3)\n",
    "    \n",
    "    for col in missing_data.index:\n",
    "        if missing_data[col] > 0:\n",
    "            # change missing_pcft to .4f\n",
    "            print(f\"  {col}: {missing_data[col]:,} ({missing_pct[col]:.3f}%)\")\n",
    "    \n",
    "    # Cardinality analysis\n",
    "    print(f\"\\nCARDINALITY ANALYSIS\")\n",
    "    cardinality = df.nunique().sort_values(ascending=False)\n",
    "    for col, count in cardinality.items():\n",
    "        print(f\"  {col}: {count:,} unique values\")\n",
    "    \n",
    "    # Categorical distributions\n",
    "    categorical_cols = ['intake_type', 'intake_condition', 'intake_reason', 'outcome_type', 'animal_type']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col.upper()} DISTRIBUTION\")\n",
    "            dist = df[col].value_counts(normalize=True).head(10)\n",
    "            for value, pct in dist.items():\n",
    "                print(f\"  {value}: {pct:.1%}\")\n",
    "    \n",
    "    # Temporal analysis\n",
    "    print(f\"\\nTEMPORAL ANALYSIS\")\n",
    "    if 'intake_date' in df.columns:\n",
    "        date_range = df['intake_date'].agg(['min', 'max'])\n",
    "        print(f\"  Intake date range: {date_range['min'].date()} to {date_range['max'].date()}\")\n",
    "        \n",
    "        # Monthly trends\n",
    "        monthly = df.set_index('intake_date').resample('M').size()\n",
    "        print(f\"  Average monthly intake: {monthly.mean():.0f} animals\")\n",
    "        print(f\"  Peak month: {monthly.idxmax().strftime('%B %Y')} ({monthly.max():,} animals)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 4. Data Cleaning & Standardization\n",
    "\n",
    "**Purpose:**  \n",
    "Align all of our sources to a common schema.\n",
    "\n",
    "> **Note:** This step enforces snake_case naming and removes accidental duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will define the full column mapping for all the DataFrames:\n",
    "COLUMN_MAP = {\n",
    "    # Animal identification\n",
    "    **{col: \"animal_id\" for col in [\"AnimalID\", \"Animal_Id\", \"Animal ID\"]}, # Using Python's dictionary operators for cleaner code!\n",
    "    **{col: \"animal_type\" for col in [\"AnimalType\", \"Animal_Type\", \"Type\"]},\n",
    "    \n",
    "    # Animal characteristics\n",
    "    **{col: \"breed\" for col in [\"PrimaryBreed\", \"Animal_Breed\", \"Breed\"]},\n",
    "    **{col: \"primary_color\" for col in [\"PrimaryColor\", \"Color\"]},\n",
    "    \"Age\": \"age\",\n",
    "    \"Date Of Birth\": \"date_of_birth\",\n",
    "    \"Sex\": \"sex\",\n",
    "    \n",
    "    # Intake information\n",
    "    **{col: \"intake_type\" for col in [\"IntakeType\", \"Intake_type\", \"Intake Type\"]},\n",
    "    **{col: \"intake_condition\" for col in [\"IntakeCondition\", \"Intake_Condition\", \"Intake Condition\"]},\n",
    "    **{col: \"intake_reason\" for col in [\"IntakeReason\", \"Reason\"]},\n",
    "    **{col: \"intake_date\" for col in [\"IntakeDate\", \"Intake_Date\", \"Intake Date\"]},\n",
    "    \n",
    "    # Outcome information\n",
    "    **{col: \"outcome_type\" for col in [\"OutcomeType\", \"outcome_type\", \"Outcome Type\"]},\n",
    "    **{col: \"outcome_date\" for col in [\"OutcomeDate\", \"Outcome_Date\", \"Outcome Date\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column standardization starting...\n",
      "\n",
      " - dallas: ['animal_id', 'animal_type', 'breed', 'kennel_number', 'kennel_status', 'tag_type', 'activity_number', 'activity_sequence', 'source_id', 'census_tract', 'council_district', 'intake_type', 'intake_subtype', 'intake_total', 'intake_reason', 'staff_id', 'intake_date', 'intake_time', 'due_out', 'intake_condition', 'hold_request', 'outcome_type', 'outcome_subtype', 'outcome_date', 'outcome_time', 'receipt_number', 'impound_number', 'service_request_number', 'outcome_condition', 'chip_status', 'animal_origin', 'additional_information', 'month', 'year']\n",
      " - san_jose: ['_id', 'animal_id', 'animalname', 'animal_type', 'primary_color', 'secondarycolor', 'breed', 'sex', 'dob', 'age', 'intake_date', 'intake_condition', 'intake_type', 'intakesubtype', 'intake_reason', 'outcome_date', 'outcome_type', 'outcomesubtype', 'outcomecondition', 'crossing', 'jurisdiction', 'lastupdate']\n",
      " - soco: ['name', 'animal_type', 'breed', 'primary_color', 'sex', 'size', 'date_of_birth', 'impound number', 'kennel number', 'animal_id', 'intake_date', 'outcome_date', 'days in shelter', 'intake_type', 'intake subtype', 'outcome_type', 'outcome subtype', 'intake_condition', 'outcome condition', 'intake jurisdiction', 'outcome jurisdiction', 'outcome zip code', 'location', 'count']\n",
      "\n",
      "---\n",
      "Column standardization complete.\n"
     ]
    }
   ],
   "source": [
    "# Apply standardization (renaming and lowercasing) to all DataFrames\n",
    "print(\"Column standardization starting...\\n\")\n",
    "CLEAN_DFS = {\n",
    "    source: standardize_columns(source, df, COLUMN_MAP)\n",
    "    for source, df in BRONZE_DFS.items()\n",
    "}\n",
    "print(\"\\n---\\nColumn standardization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 5. Value Mapping & Data Type Enforcement\n",
    "\n",
    "**Purpose:**  \n",
    "Convert raw categorical codes into clean, analysis-ready categories and cast explicit dtypes.  \n",
    "\n",
    "> **Note:** Using `category` dtype optimizes memory and speeds up grouping operations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── SILVER DTYPE MAPPING ───\n",
    "# Define explicit pandas dtypes for key columns\n",
    "SILVER_DTYPES = {\n",
    "    \"intake_type\"     : \"category\",\n",
    "    \"intake_condition\": \"category\",\n",
    "    \"intake_reason\"   : \"object\",\n",
    "    \"intake_date\"     : \"datetime64[ns]\",\n",
    "    \"outcome_type\"    : \"category\",\n",
    "    \"outcome_date\"    : \"datetime64[ns]\",\n",
    "}\n",
    "\n",
    "# ─── VALUE MAPPINGS ───\n",
    "\n",
    "# 1. intake_type mapping\n",
    "INTAKE_TYPE_MAP = {\n",
    "    \"BORN HERE\":           \"born_at_shelter\",\n",
    "    \"CONFISCATE\":          \"confiscated\",\n",
    "    \"CONFISCATED\":         \"confiscated\",\n",
    "    \"DISPO REQ\":           \"disposal_request\",\n",
    "    \"DISPOS REQ\":          \"disposal_request\",\n",
    "    \"EUTH REQ\":            \"euthanasia_request\",\n",
    "    \"FOSTER\":              \"foster\",\n",
    "    \"KEEPSAFE\":            \"protective_custody\",\n",
    "    \"QUARANTINE\":          \"protective_custody\",\n",
    "    \"RESOURCE\":            \"treatment\",\n",
    "    \"TREATMENT\":           \"treatment\",\n",
    "    \"RETURN\":              \"return_to_owner\",\n",
    "    \"NEUTER\":              \"spay_neuter\",\n",
    "    \"S/N CLINIC\":          \"spay_neuter\",\n",
    "    \"SPAY\":                \"spay_neuter\",\n",
    "    \"STRAY\":               \"stray\",\n",
    "    \"TNR\":                 \"stray\",\n",
    "    \"ADOPTION RETURN\":     \"surrender\",\n",
    "    \"OS APPT\":             \"surrender\",\n",
    "    \"OWNER SUR\":           \"surrender\",\n",
    "    \"OWNER SURRENDER\":     \"surrender\",\n",
    "    \"TRANSFER\":            \"transfer\",\n",
    "    \"WILDLIFE\":            \"wildlife\",\n",
    "}\n",
    "\n",
    "# 2. intake_condition mapping\n",
    "INTAKE_CONDITION_MAP = {\n",
    "    \"GERIATRIC\":            \"age_related\",\n",
    "    \"UNDERAGE\":             \"age_related\",\n",
    "    \"AGGRESSIVE\":           \"behavioral\",\n",
    "    \"BEH M\":                \"behavioral\",\n",
    "    \"BEH R\":                \"behavioral\",\n",
    "    \"BEH U\":                \"behavioral\",\n",
    "    \"FERAL\":                \"behavioral\",\n",
    "    \"CRITICAL\":             \"critical\",\n",
    "    \"FATAL\":                \"critical\",\n",
    "    \"UNTREATABLE\":          \"critical\",\n",
    "    \"DECEASED\":             \"deceased\",\n",
    "    \"DEAD\":                 \"deceased\",\n",
    "    \"APP WNL\":              \"healthy\",\n",
    "    \"NORMAL\":               \"healthy\",\n",
    "    \"HEALTHY\":              \"healthy\",\n",
    "    \"APP INJ\":              \"medical\",\n",
    "    \"APP SICK\":             \"medical\",\n",
    "    \"MED EMERG\":            \"medical\",\n",
    "    \"MED M\":                \"medical\",\n",
    "    \"MED R\":                \"medical\",\n",
    "    \"MED SEV\":              \"medical\",\n",
    "    \"TREATABLE/MANAGEABLE\":\"medical\",\n",
    "    \"TREATABLE/REHAB\":      \"medical\",\n",
    "    \"NURSING\":              \"reproductive\",\n",
    "    \"PREGNANT\":             \"reproductive\",\n",
    "    \"UNKNOWN\":              \"unknown\",\n",
    "}\n",
    "\n",
    "# 3. intake_reason mapping\n",
    "INTAKE_REASON_MAP = {\n",
    "    \"FOR ADOPT\":              \"for_adoption\",\n",
    "    \"FOR PLCMNT\":             \"for_adoption\",\n",
    "    \"IP ADOPT\":               \"for_adoption\",\n",
    "    \"BEHAVIOR\":               \"behavior\",\n",
    "    \"AGG ANIMAL\":             \"behavior\",\n",
    "    \"AGG PEOPLE\":             \"behavior\",\n",
    "    \"BITES\":                  \"behavior\",\n",
    "    \"CHASES ANI\":             \"behavior\",\n",
    "    \"DESTRUC IN\":             \"behavior\",\n",
    "    \"ESCAPES\":                \"behavior\",\n",
    "    \"HOUSE SOIL\":             \"behavior\",\n",
    "    \"HYPER\":                  \"behavior\",\n",
    "    \"NOFRIENDLY\":             \"behavior\",\n",
    "    \"PICA\":                   \"behavior\",\n",
    "    \"BREED REST\":             \"breed_restriction\",\n",
    "    \"OWR REQ EU\":             \"owner_requested_euthanasia\",\n",
    "    \"IP EUTH\":                \"owner_requested_euthanasia\",\n",
    "    \"MEDICAL\":                \"medical\",\n",
    "    \"SURGERY\":                \"medical\",\n",
    "    \"VET CARE\":               \"medical\",\n",
    "    \"OTHER\":                  \"other\",\n",
    "    \"OTHRINTAKS\":             \"other\",\n",
    "    \"CANTAFFORD\":             \"owner_surrender\",\n",
    "    \"EVICTION\":               \"owner_surrender\",\n",
    "    \"FINANCIAL\":              \"owner_surrender\",\n",
    "    \"HOUSING\":                \"owner_surrender\",\n",
    "    \"LLCONFLICT\":             \"owner_surrender\",\n",
    "    \"LOSSHOUSNG\":             \"owner_surrender\",\n",
    "    \"PETDEPFEE\":              \"owner_surrender\",\n",
    "    \"LANDLORD\":               \"owner_surrender\",\n",
    "    \"MOVE\":                   \"owner_surrender\",\n",
    "    \"NO HOME\":                \"owner_surrender\",\n",
    "    \"OWR DEATH\":              \"owner_surrender\",\n",
    "    \"PERLIFECNG\":             \"owner_surrender\",\n",
    "    \"PERSNLISSU\":             \"owner_surrender\",\n",
    "    \"TEMLIFECNG\":             \"owner_surrender\",\n",
    "    \"ALLERGIC\":               \"owner_surrender\",\n",
    "    \"CHILD PROB\":             \"owner_surrender\",\n",
    "    \"NO TIME\":                \"owner_surrender\",\n",
    "    \"OWNER DIED\":             \"owner_surrender\",\n",
    "    \"OWNER PROB\":             \"owner_surrender\",\n",
    "    \"TRAVEL\":                 \"owner_surrender\",\n",
    "    \"NOTRIGHTFT\":             \"owner_surrender\",\n",
    "    \"ATTENTION\":              \"owner_surrender\",\n",
    "    \"OTHER PET\":              \"owner_surrender\",\n",
    "    \"TOO BIG\":                \"owner_surrender\",\n",
    "    \"TOO MANY\":               \"owner_surrender\",\n",
    "    \"SHORT-TERM\":             \"temporary_care\",\n",
    "    \"TNR CLINIC\":             \"trap_neuter_return\",\n",
    "    \"TRANSFER\":               \"transfer\",\n",
    "}\n",
    "\n",
    "# 4. outcome_type mapping\n",
    "OUTCOME_TYPE_MAP = {\n",
    "    \"ADOPTION\":               \"adoption\",\n",
    "    \"RESCUE\":                 \"adoption\",\n",
    "    \"DIED\":                   \"deceased\",\n",
    "    \"EUTH\":                   \"euthanasia\",\n",
    "    \"EUTHANIZE\":              \"euthanasia\",\n",
    "    \"EUTHANIZED\":             \"euthanasia\",\n",
    "    \"REQ EUTH\":               \"euthanasia\",\n",
    "    \"DISPOSAL\":               \"disposal\",\n",
    "    \"ESCAPED/STOLEN\":         \"escaped\",\n",
    "    \"FOUND ANIM\":             \"found\",\n",
    "    \"FOUND EXP\":              \"found\",\n",
    "    \"LOST EXP\":               \"lost\",\n",
    "    \"MISSING\":                \"lost\",\n",
    "    \"FOSTER\":                 \"foster\",\n",
    "    \"TREATMENT\":              \"treatment\",\n",
    "    \"VET\":                    \"treatment\",\n",
    "    \"CLOSED\":                 \"other\",\n",
    "    \"OTHER\":                  \"other\",\n",
    "    \"RETURN TO OWNER\":        \"return_to_owner\",\n",
    "    \"RETURNED TO OWNER\":      \"return_to_owner\",\n",
    "    \"RTF\":                    \"return_to_field\",\n",
    "    \"RTO\":                    \"return_to_owner\",\n",
    "    \"RTOS\":                   \"return_to_owner\",\n",
    "    \"NEUTER\":                 \"spay_neuter\",\n",
    "    \"SNR\":                    \"spay_neuter\",\n",
    "    \"SPAY\":                   \"spay_neuter\",\n",
    "    \"TNR\":                    \"trap_neuter_release\",\n",
    "    \"TRANSFER\":               \"transfer\",\n",
    "    \"WILDLIFE\":               \"wildlife\",\n",
    "}\n",
    "\n",
    "# Final assembly\n",
    "VALUE_MAPPINGS = {\n",
    "    \"intake_type\"     : INTAKE_TYPE_MAP,\n",
    "    \"intake_condition\": INTAKE_CONDITION_MAP,\n",
    "    \"intake_reason\"   : INTAKE_REASON_MAP,\n",
    "    \"outcome_type\"    : OUTCOME_TYPE_MAP,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:** The cell below reveals inconsistencies across datasets where identical concepts are represented with slight variations (Example: \"CONFISCATED\", \"CONFISCATE\", \"CONFISCTED\"). These inconsistencies would create data fragmentation in downstream analysis.\n",
    "\n",
    "The `apply_silver_transforms` function addresses these issues by:\n",
    "\n",
    "1. **Enforcing uniform data types** across all datasets\n",
    "2. **Standardizing categorical values** using the VALUE_MAPPINGS dictionary\n",
    "3. **Validating temporal data** and handling future dates\n",
    "4. **Gracefully handling missing columns** across different data sources\n",
    "\n",
    "This ensures all datasets share a common vocabulary and data structure for reliable analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "BEFORE VALUE HARMONIZATION:\n",
      "==============================\n",
      "\n",
      "DALLAS DATASET:\n",
      "   BEFORE intake_type: ['CONFISCATED', 'DISPOS REQ', 'FOSTER', 'KEEPSAFE', 'OWNER SURRENDER', 'RESOURCE', 'STRAY', 'TNR', 'TRANSFER', 'TREATMENT', 'WILDLIFE']\n",
      "   BEFORE intake_condition: ['APP INJ', 'APP SICK', 'APP WNL', 'CRITICAL', 'DECEASED', 'FATAL', 'GERIATRIC', 'NORMAL', 'UNDERAGE']\n",
      "   BEFORE intake_reason: ['BEHAVIOR', 'BREED REST', 'CANTAFFORD', 'EVICTION', 'FINANCIAL', 'FOR ADOPT', 'FOR PLCMNT', 'HOUSING', 'LLCONFLICT', 'LOSSHOUSNG', 'MEDICAL', 'NOTRIGHTFT', 'OTHER', 'OTHRINTAKS', 'OWR DEATH', 'OWR REQ EU', 'PERLIFECNG', 'PERSNLISSU', 'PETDEPFEE', 'SHORT-TERM', 'STRAY', 'SURGERY', 'TEMLIFECNG', 'TNR CLINIC', 'TRANSFER', 'VET CARE']\n",
      "   BEFORE outcome_type: ['ADOPTION', 'CLOSED', 'DIED', 'DISPOSAL', 'EUTHANIZED', 'FOSTER', 'FOUND EXP', 'LOST EXP', 'MISSING', 'OTHER', 'RETURNED TO OWNER', 'SNR', 'TNR', 'TRANSFER', 'TREATMENT', 'WILDLIFE']\n",
      "\n",
      "SAN_JOSE DATASET:\n",
      "   BEFORE intake_type: ['CONFISCATE', 'DISPO REQ', 'EUTH REQ', 'FOSTER', 'NEUTER', 'OWNER SUR', 'RETURN', 'S/N CLINIC', 'SPAY', 'STRAY', 'TRANSFER', 'WILDLIFE']\n",
      "   BEFORE intake_condition: ['AGGRESSIVE', 'BEH M', 'BEH R', 'BEH U', 'DEAD', 'FERAL', 'HEALTHY', 'MED EMERG', 'MED M', 'MED R', 'MED SEV', 'NURSING', 'PREGNANT']\n",
      "   BEFORE intake_reason: ['AGG ANIMAL', 'AGG PEOPLE', 'ALLERGIC', 'ATTENTION', 'BITES', 'CHASES ANI', 'CHILD PROB', 'DESTRUC IN', 'ESCAPES', 'HOUSE SOIL', 'HYPER', 'IP ADOPT', 'IP EUTH', 'LANDLORD', 'MOVE', 'NO HOME', 'NO TIME', 'NOFRIENDLY', 'OTHER PET', 'OWNER DIED', 'OWNER PROB', 'PICA', 'TOO BIG', 'TOO MANY', 'TRAVEL']\n",
      "   BEFORE outcome_type: ['ADOPTION', 'DIED', 'DISPOSAL', 'EUTH', 'FOSTER', 'FOUND ANIM', 'LOST EXP', 'MISSING', 'NEUTER', 'REQ EUTH', 'RESCUE', 'RTF', 'RTO', 'SPAY', 'TRANSFER']\n",
      "\n",
      "SOCO DATASET:\n",
      "   BEFORE intake_type: ['ADOPTION RETURN', 'BORN HERE', 'CONFISCATE', 'OS APPT', 'OWNER SURRENDER', 'QUARANTINE', 'STRAY', 'TRANSFER']\n",
      "   BEFORE intake_condition: ['HEALTHY', 'TREATABLE/MANAGEABLE', 'TREATABLE/REHAB', 'UNKNOWN', 'UNTREATABLE']\n",
      "   BEFORE outcome_type: ['ADOPTION', 'DIED', 'DISPOSAL', 'ESCAPED/STOLEN', 'EUTHANIZE', 'RETURN TO OWNER', 'RTOS', 'TRANSFER', 'VET']\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 30)\n",
    "print(\"BEFORE VALUE HARMONIZATION:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "categorical_cols = ['intake_type', 'intake_condition', 'intake_reason', 'outcome_type']\n",
    "\n",
    "for source, df in CLEAN_DFS.items():\n",
    "    print(f\"\\n{source.upper()} DATASET:\")\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            unique_values = df[col].dropna().unique()\n",
    "            print(f\"   BEFORE {col}: {sorted(unique_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 6. Execute Transformations\n",
    "\n",
    "**Purpose:**  Orchestrate the cleaning in a single, easy-to-read cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Found 1 future dates in intake_date for dallas\n",
      "         Latest future date: 2025-09-27\n",
      "         Setting future dates to NaT (Not a Time)\n",
      "Silver transformations applied successfully!\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations\n",
    "SILVER_DFS = {\n",
    "    source: apply_silver_transforms(df, source)\n",
    "    for source, df in CLEAN_DFS.items()\n",
    "}\n",
    "\n",
    "print(\"Silver transformations applied successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "AFTER VALUE HARMONIZATION:\n",
      "------------------------------\n",
      "\n",
      "DALLAS DATASET:\n",
      "   AFTER: intake_type: ['confiscated', 'disposal_request', 'foster', 'protective_custody', 'stray', 'surrender', 'transfer', 'treatment', 'wildlife']\n",
      "   AFTER: intake_condition: ['age_related', 'critical', 'deceased', 'healthy', 'medical']\n",
      "   AFTER: intake_reason: ['behavior', 'breed_restriction', 'for_adoption', 'medical', 'other', 'owner_requested_euthanasia', 'owner_surrender', 'temporary_care', 'transfer', 'trap_neuter_return', 'unknown']\n",
      "   AFTER: outcome_type: ['adoption', 'deceased', 'disposal', 'euthanasia', 'foster', 'found', 'lost', 'other', 'return_to_owner', 'spay_neuter', 'transfer', 'trap_neuter_release', 'treatment', 'wildlife']\n",
      "\n",
      "SAN_JOSE DATASET:\n",
      "   AFTER: intake_type: ['confiscated', 'disposal_request', 'euthanasia_request', 'foster', 'return_to_owner', 'spay_neuter', 'stray', 'surrender', 'transfer', 'wildlife']\n",
      "   AFTER: intake_condition: ['behavioral', 'deceased', 'healthy', 'medical', 'reproductive']\n",
      "   AFTER: intake_reason: ['behavior', 'for_adoption', 'owner_requested_euthanasia', 'owner_surrender', 'unknown']\n",
      "   AFTER: outcome_type: ['adoption', 'deceased', 'disposal', 'euthanasia', 'foster', 'found', 'lost', 'other', 'return_to_field', 'return_to_owner', 'spay_neuter', 'transfer']\n",
      "\n",
      "SOCO DATASET:\n",
      "   AFTER: intake_type: ['born_at_shelter', 'confiscated', 'protective_custody', 'stray', 'surrender', 'transfer']\n",
      "   AFTER: intake_condition: ['critical', 'healthy', 'medical', 'unknown']\n",
      "   AFTER: intake_reason: ['unknown']\n",
      "   AFTER: outcome_type: ['adoption', 'deceased', 'disposal', 'escaped', 'euthanasia', 'other', 'return_to_owner', 'transfer', 'treatment']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 30)\n",
    "print(\"AFTER VALUE HARMONIZATION:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for source, df in SILVER_DFS.items():\n",
    "    print(f\"\\n{source.upper()} DATASET:\")\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            unique_values = df[col].dropna().unique()\n",
    "            print(f\"   AFTER: {col}: {sorted(unique_values)}\")\n",
    "\n",
    "# print(f\"\\nVALUE HARMONIZATION SUMMARY:\")\n",
    "# print(f\"   - Mapped {len(VALUE_MAPPINGS)} categorical variables to consistent values\")\n",
    "# print(f\"   - Unified terminology across Dallas, San Jose, and Sonoma County datasets\")\n",
    "# print(f\"   - Ready for cross-shelter analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 7. Create Silver & Quality Checks\n",
    "\n",
    "**Purpose:**  \n",
    "Combine each source’s cleaned DataFrame into the final `silver_df` according to our `FINAL_SCHEMA`, and if desired, do a data quality assesment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SCHEMA = [\n",
    "    \"animal_id\", \"animal_type\", \"breed\", \"primary_color\", \"age\", \"date_of_birth\", \"sex\",\n",
    "    \"intake_type\", \"intake_condition\", \"intake_reason\", \"intake_date\",\n",
    "    \"outcome_type\", \"outcome_date\", \"region\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver dataset created: 105,633 records × 14 columns\n",
      "Duplicates removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Here we create the final silver dataset\n",
    "silver_df = create_silver_dataset(SILVER_DFS, FINAL_SCHEMA)\n",
    "print(f\"Silver dataset created: {silver_df.shape[0]:,} records × {silver_df.shape[1]} columns\")\n",
    "print(f\"Duplicates removed: {sum(df.shape[0] for df in SILVER_DFS.values()) - silver_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Assessment\n",
    "\n",
    "Comprehensive quality checks and data profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY PROFILE\n",
      "============================================================\n",
      "\n",
      "DATASET OVERVIEW\n",
      "Total records: 105,633\n",
      "Total columns: 14\n",
      "\n",
      "MISSING DATA ANALYSIS\n",
      "  breed: 39 (0.037%)\n",
      "  primary_color: 65,079 (61.609%)\n",
      "  age: 95,633 (90.533%)\n",
      "  date_of_birth: 82,509 (78.109%)\n",
      "  sex: 65,079 (61.609%)\n",
      "  intake_date: 1 (0.001%)\n",
      "  outcome_date: 1,448 (1.371%)\n",
      "\n",
      "CARDINALITY ANALYSIS\n",
      "  animal_id: 85,432 unique values\n",
      "  date_of_birth: 6,572 unique values\n",
      "  intake_date: 3,982 unique values\n",
      "  outcome_date: 3,597 unique values\n",
      "  breed: 1,221 unique values\n",
      "  primary_color: 394 unique values\n",
      "  age: 61 unique values\n",
      "  outcome_type: 16 unique values\n",
      "  intake_type: 13 unique values\n",
      "  intake_reason: 11 unique values\n",
      "  sex: 10 unique values\n",
      "  intake_condition: 8 unique values\n",
      "  animal_type: 6 unique values\n",
      "  region: 3 unique values\n",
      "\n",
      "INTAKE_TYPE DISTRIBUTION\n",
      "  stray: 59.2%\n",
      "  surrender: 12.7%\n",
      "  foster: 12.1%\n",
      "  confiscated: 6.7%\n",
      "  treatment: 3.2%\n",
      "  protective_custody: 1.8%\n",
      "  wildlife: 1.7%\n",
      "  disposal_request: 1.3%\n",
      "  transfer: 0.7%\n",
      "  spay_neuter: 0.4%\n",
      "\n",
      "INTAKE_CONDITION DISTRIBUTION\n",
      "  healthy: 68.0%\n",
      "  medical: 12.9%\n",
      "  unknown: 10.6%\n",
      "  critical: 3.2%\n",
      "  age_related: 1.9%\n",
      "  deceased: 1.9%\n",
      "  reproductive: 0.8%\n",
      "  behavioral: 0.7%\n",
      "\n",
      "INTAKE_REASON DISTRIBUTION\n",
      "  unknown: 45.3%\n",
      "  other: 30.9%\n",
      "  owner_surrender: 7.4%\n",
      "  medical: 6.4%\n",
      "  for_adoption: 6.0%\n",
      "  transfer: 1.7%\n",
      "  behavior: 1.3%\n",
      "  trap_neuter_return: 0.4%\n",
      "  temporary_care: 0.4%\n",
      "  breed_restriction: 0.1%\n",
      "\n",
      "OUTCOME_TYPE DISTRIBUTION\n",
      "  adoption: 29.1%\n",
      "  return_to_owner: 15.5%\n",
      "  transfer: 14.7%\n",
      "  euthanasia: 12.9%\n",
      "  foster: 11.7%\n",
      "  lost: 3.3%\n",
      "  other: 2.3%\n",
      "  treatment: 2.2%\n",
      "  disposal: 1.9%\n",
      "  trap_neuter_release: 1.8%\n",
      "\n",
      "ANIMAL_TYPE DISTRIBUTION\n",
      "  DOG: 59.1%\n",
      "  CAT: 33.2%\n",
      "  OTHER: 3.1%\n",
      "  BIRD: 3.0%\n",
      "  WILDLIFE: 1.5%\n",
      "  LIVESTOCK: 0.0%\n",
      "\n",
      "TEMPORAL ANALYSIS\n",
      "  Intake date range: 2013-08-16 to 2025-05-22\n",
      "  Average monthly intake: 744 animals\n",
      "  Peak month: July 2024 (6,079 animals)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/lrkcgdlx3332x9brp_np1l_c0000gn/T/ipykernel_23756/3662161463.py:180: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly = df.set_index('intake_date').resample('M').size()\n"
     ]
    }
   ],
   "source": [
    "# Lets generate the data profile for the silver dataset\n",
    "generate_data_overview(silver_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
