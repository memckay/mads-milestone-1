{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bronze Data Load\n",
    "\n",
    "In this notebook, we will be extracting and loading the documents into the Bronze layer.  \n",
    "\n",
    "The data will be stored as-is from the source in its raw state, without any transformations, cleaning, or modification.\n",
    "\n",
    "For more information on Medallion Architecture, see [Databricks Glossary](https://www.databricks.com/glossary/medallion-architecture) (Databricks, n.d.).\n",
    "\n",
    "-----\n",
    "\n",
    "### References  \n",
    "Databricks. (n.d.). *Medallion Architecture*. Retrieved May 10, 2025, from [https://www.databricks.com/glossary/medallion-architecture](https://www.databricks.com/glossary/medallion-architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages (from kagglehub) (2.32.3)\n",
      "Collecting tqdm (from kagglehub)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages (from requests->kagglehub) (2024.7.4)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, kagglehub\n",
      "Successfully installed kagglehub-0.3.12 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraitons\n",
    "KAGGLE_DATASET_NAMES = [\n",
    "    \"aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes\"\n",
    "]\n",
    "DATA_DIRECTORY = \"data-assets\"\n",
    "\n",
    "# You should set this to true if you modify files and need to force the dataset to be re-downlaoded\n",
    "CLEAR_CACHE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will load the Datasets into our `data-asset/bronze` folder.\n",
    "\n",
    "This seeds our **bronze** layer, which has raw, unprocessed datasets. Keeping these is valuable as it allows us to reprocess data if our methods change, and helps with auditing and troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache found. Deleting cache...\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.25M/9.25M [00:01<00:00, 8.51MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded dataset files in temp path: /Users/mariamckay/.cache/kagglehub/datasets/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes/versions/1\n",
      "Moved aac_intakes_outcomes.csv to current working directory.\n",
      "Moved aac_intakes.csv to current working directory.\n",
      "Moved aac_outcomes.csv to current working directory.\n"
     ]
    }
   ],
   "source": [
    "# Download latest version of the dataset from kaggle, for each dataset\n",
    "for dataset_name in KAGGLE_DATASET_NAMES:\n",
    "\n",
    "    # Clear downloads cache if present, to ensure we are getting fresh data\n",
    "    # This helps ensure we are getting consistent results across different machines\n",
    "    if CLEAR_CACHE and os.path.exists(os.path.join(os.path.expanduser(\"~\"), \".cache/kagglehub/datasets\", dataset_name)):\n",
    "        print(\"Cache found. Deleting cache...\")\n",
    "        subprocess.run([\"rm\", \"-rf\", os.path.join(os.path.expanduser(\"~\"), \".cache/kagglehub/datasets\", dataset_name)])\n",
    " \n",
    "    # Download the dataset from kaggle\n",
    "    temp = kagglehub.dataset_download(\"aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes\")\n",
    "    print(\"Downloaded dataset files in temp path:\", temp)\n",
    "\n",
    "    # Move the dataset files to the current working directory. Create the directory if it does not exist\n",
    "    data_dir = f\"{DATA_DIRECTORY}/bronze/{dataset_name}\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        print(f\"Created directory {data_dir}.\")\n",
    "\n",
    "    for file in os.listdir(temp):\n",
    "        os.rename(os.path.join(temp, file), os.path.join(os.path.relpath(\".\"), data_dir, file))\n",
    "        print(f\"Moved {file} to current working directory in bronze.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
