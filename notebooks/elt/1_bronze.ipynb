{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bronze Data Load\n",
    "\n",
    "**Purpose:**  \n",
    "Ingest raw data from all sources into the Bronze layer with **no business logic** or feature engineering—only the bare minimum of cleaning required for schema alignment.\n",
    "\n",
    "**What this notebook does:**  \n",
    "1. **Reads** data from:  \n",
    "   - San Jose API (JSON → DataFrame)  \n",
    "   - Dallas CSV  \n",
    "   - SoCo CSV  \n",
    "2. **Materializes** the data into our \"tables\":\n",
    "   - `data-assets/bronze/dallas_df.parquet`\n",
    "   - `data-assets/bronze/san_jose_df.parquet`\n",
    "   - `data-assets/bronze/soco_df.parquet`\n",
    "\n",
    "This data will be used when creating [Silver](./2_1_silver.ipynb), where it will be cleaned and pre-processed to allow us to work with higher quality data.\n",
    "\n",
    "For more on Medallion Architecture, see [Databricks Glossary: Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture) (Databricks, n.d.).\n",
    "\n",
    "---\n",
    "\n",
    "### References  \n",
    "Databricks. (n.d.). *Medallion Architecture*. Retrieved May 10, 2025, from https://www.databricks.com/glossary/medallion-architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup](#setup)  \n",
    "   - Install project dependencies from requirements.txt\n",
    "   - Import essential libraries (os, requests, pandas)\n",
    "\n",
    "2. [Configuration](#configuration)  \n",
    "   - Define data directory paths\n",
    "   - Set up API endpoints and parameters\n",
    "   - Configure date column mappings\n",
    "   - Centralize all file paths for reproducibility\n",
    "\n",
    "3. [Data Loading](#data-loading)  \n",
    "   - Fetch and parse San Jose animal shelter data from API\n",
    "   - Read Dallas shelter data from CSV\n",
    "   - Import Sonoma County shelter data from CSV\n",
    "   - Save all datasets as parquet files in bronze layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "**Purpose:**  \n",
    "Ensure the environment has all necessary libraries installed and imported.  \n",
    "- `%pip install -r ../../requirements.txt` installs dependencies. \n",
    "\n",
    "> **Note:** we use a project-wide `requirements.txt` for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub==0.3.12 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 1)) (0.3.12)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 2)) (0.13.2)\n",
      "Requirement already satisfied: pandas==2.2.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib==3.9.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 4)) (3.9.2)\n",
      "Requirement already satisfied: sodapy==2.2.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 5)) (2.2.0)\n",
      "Collecting pyarrow==20.0.0 (from -r ../../requirements.txt (line 6))\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from kagglehub==0.3.12->-r ../../requirements.txt (line 1)) (24.0)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from kagglehub==0.3.12->-r ../../requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from kagglehub==0.3.12->-r ../../requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from kagglehub==0.3.12->-r ../../requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from seaborn==0.13.2->-r ../../requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 4)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 4)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 4)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r ../../requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from requests->kagglehub==0.3.12->-r ../../requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from requests->kagglehub==0.3.12->-r ../../requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from requests->kagglehub==0.3.12->-r ../../requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from requests->kagglehub==0.3.12->-r ../../requirements.txt (line 1)) (2024.6.2)\n",
      "Downloading pyarrow-20.0.0-cp311-cp311-macosx_12_0_arm64.whl (30.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.9/30.9 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-20.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 2. Configuration\n",
    "\n",
    "**Purpose:**  \n",
    "Centralize all “magic” values—file paths, API endpoints, parameters, and date-column names to make it easy to load everything locally.\n",
    "- Makes the notebook reproducible.  \n",
    "- Keeps the loading cells concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Configuration ───\n",
    "\n",
    "# File paths for the CSV files\n",
    "DATA_DIR = \"../../data-assets/_raw\"\n",
    "CSV_PATHS = {\n",
    "    \"dallas\": os.path.join(\n",
    "        DATA_DIR,\n",
    "        \"Dallas_Animal_Shelter_Data_Fiscal_Year_2023_-_2025_20250516.csv\"\n",
    "    ),\n",
    "    \"soco\": os.path.join(\n",
    "        DATA_DIR,\n",
    "        \"SoCo_Animal_Shelter_Intake_and_Outcome_20250519.csv\"\n",
    "    ),\n",
    "}\n",
    "API_PATHS = {\n",
    "    \"san_jose\": {\n",
    "        \"base_url\":    \"https://data.sanjoseca.gov/api/3/action/datastore_search\",\n",
    "        # Setting this limit tells the API to retyrn up to 10,000 records in a single call without\n",
    "        # overwhelming the API or the network with an unbounded payload.\n",
    "        # This helps us work around the the CKAN API's default which is 100 records per request.\n",
    "        \"params\":      {\"resource_id\": \"f3354a37-7e03-41f8-a94d-3f720389a68a\", \"limit\": 10000}, \n",
    "    }\n",
    "}\n",
    "\n",
    "# ─── Date columns to parse ───\n",
    "DATE_COLS = {\n",
    "    \"san_jose\": [\"IntakeDate\", \"OutcomeDate\"],\n",
    "    \"dallas\":   [\"Intake_Date\", \"Outcome_Date\"],\n",
    "    \"soco\":     [\"Intake Date\", \"Outcome Date\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 3. Data Loading\n",
    "\n",
    "**Purpose:**  \n",
    "Pull raw data into pandas DataFrames:  \n",
    "1. Call the San Jose API and parse its JSON response.  \n",
    "2. Read the Dallas + SoCo CSV files, converting date strings to `datetime64`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Data Loading ───\n",
    "\n",
    "# San Jose API\n",
    "resp = requests.get(\n",
    "    API_PATHS[\"san_jose\"][\"base_url\"], \n",
    "    params=API_PATHS[\"san_jose\"][\"params\"]\n",
    ")\n",
    "resp.raise_for_status()\n",
    "san_jose_df = pd.DataFrame(resp.json()[\"result\"][\"records\"])\n",
    "\n",
    "# Parse as datetimes\n",
    "for col in DATE_COLS[\"san_jose\"]:\n",
    "    san_jose_df[col] = pd.to_datetime(san_jose_df[col], errors=\"coerce\")\n",
    "\n",
    "# Dallas and SoCo CSVs\n",
    "dallas_df = pd.read_csv(\n",
    "    CSV_PATHS[\"dallas\"],\n",
    "    parse_dates=DATE_COLS[\"dallas\"],\n",
    "    low_memory=False\n",
    ")\n",
    "soco_df = pd.read_csv(\n",
    "    CSV_PATHS[\"soco\"],\n",
    "    parse_dates=DATE_COLS[\"soco\"],\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 4. Materialize Bronze\n",
    "\n",
    "**Purpose:**  \n",
    "Materialize the Bronze data, as is from the source.\n",
    "\n",
    "This allows us to have a copy of the data for reproducability, and if we need to re-build Silver. By materializing this data, we avoid re-incurring the costs of pulling down data from an API/download a csv, and store it as-is for future use-cases, in a parquet format.\n",
    "\n",
    "Since we do not have a Database, as is common when using Medallion architecture, we are materializing the data by writing it to `.parquet`. Parquet allows for faster analysis, preserves data types for data, and is an efficient standard for data-storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved san_jose_df to ../../data-assets/bronze/san_jose_df.parquet\n",
      "Saved dallas_df to ../../data-assets/bronze/dallas_df.parquet\n",
      "Saved soco_df to ../../data-assets/bronze/soco_df.parquet\n"
     ]
    }
   ],
   "source": [
    "BRONZE_DIR = \"../../data-assets/bronze\"\n",
    "\n",
    "dfs = [san_jose_df, dallas_df, soco_df]\n",
    "\n",
    "for df in dfs:\n",
    "    df_name = [name for name, obj in globals().items() if obj is df][0]\n",
    "    df.to_parquet(os.path.join(BRONZE_DIR, f\"{df_name}.parquet\"), index=False)\n",
    "    print(f\"Saved {df_name} to {BRONZE_DIR}/{df_name}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
