{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silver Data Cleaning\n",
    "\n",
    "**Purpose:**  \n",
    "Clean raw data from the [Bronze](./1_bronze.ipynb) layer, to make a large data asset that contains all data that is of interest to us. This includes but is not limited to renaming columns, consolidating field types, consolidating field values, handling nulls and bad data, deduplicating data, and more.\n",
    "\n",
    "**What this notebook does:**  \n",
    "1. **Renames** columns to a common, lowercase, snake_case style  \n",
    "2. **Tags** each row with its `source` (provenance)  \n",
    "3. **Deduplicates** any exact‐duplicate records  \n",
    "4. **Cleans** any data that requires cleaning.\n",
    "\n",
    "This data will be used when creating [Gold](./3_gold.ipynb), where tailored data assets will be created to efficiently answer specific questions.\n",
    "\n",
    "\n",
    "For more on Medallion Architecture, see [Databricks Glossary: Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture) (Databricks, n.d.).\n",
    "\n",
    "---\n",
    "\n",
    "### References  \n",
    "Databricks. (n.d.). *Medallion Architecture*. Retrieved May 10, 2025, from https://www.databricks.com/glossary/medallion-architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup](#setup)  \n",
    "   Install required packages and import libraries.  \n",
    "\n",
    "2. [Configuration](#configuration)  \n",
    "   Define all file paths, API parameters, and date-column lists in one place for reproducibility.  \n",
    "\n",
    "3. [Data Cleaning & Standardization](#data-cleaning--standardization)  \n",
    "   Rename columns, lowercase them, and drop duplicates so all sources share the same schema.  \n",
    "\n",
    "4. [Data Merging & Harmonization](#data-merging--harmonization)  \n",
    "   Stack the three sources into one “bronze” table, tag each row by origin, and enforce dtypes.  \n",
    "\n",
    "5. [Quick Exploratory Checks](#quick-exploratory-checks)  \n",
    "   Check missing values, unique counts, distributions, date ranges, and monthly trends.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "**Purpose:**  \n",
    "Ensure the environment has all necessary libraries installed and imported.  \n",
    "- `%pip install -r ../../requirements.txt` installs dependencies. \n",
    "\n",
    "> **Note:** we use a project-wide `requirements.txt` for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn==0.13.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 1)) (0.13.2)\n",
      "Requirement already satisfied: pandas==2.2.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib==3.9.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 3)) (3.9.2)\n",
      "Requirement already satisfied: pyarrow==20.0.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from -r ../../requirements.txt (line 4)) (20.0.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from seaborn==0.13.2->-r ../../requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas==2.2.2->-r ../../requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib==3.9.2->-r ../../requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r ../../requirements.txt (line 2)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Below, we define our Bronze Data Assets, so that we can work with them. We also define maps that will help us process the data and join different dataframes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRONZE_DIR = \"../../data-assets/bronze\"\n",
    "BRONZE_FILE_NAME = \"{}_df.parquet\"\n",
    "\n",
    "BRONZE_FILES = [\"dallas\", \"san_jose\", \"soco\"]\n",
    "BRONZE_FILE_PATHS = {\n",
    "    file: os.path.join(BRONZE_DIR, BRONZE_FILE_NAME.format(file)) for file in BRONZE_FILES \n",
    "}\n",
    "BRONZE_DFS = {\n",
    "    file: pd.read_parquet(path) for file, path in BRONZE_FILE_PATHS.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Standardization\n",
    "\n",
    "**Purpose:**  \n",
    "Clean up and harmonize column names across sources:  \n",
    "- Apply a single `COLUMN_MAP` dict.  \n",
    "- Lowercase everything for consistency.  \n",
    "- Drop unintended duplicates.  \n",
    "\n",
    "This ensures downstream steps can assume a uniform schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Data Cleaning ───\n",
    "\n",
    "# Here we will define the full column mapping:\n",
    "COLUMN_MAP = {\n",
    "    # Animal ID\n",
    "    \"AnimalID\":      \"animal_id\",\n",
    "    \"Animal_Id\":     \"animal_id\",\n",
    "    \"Animal ID\":     \"animal_id\",\n",
    "    # Animal Type\n",
    "    \"AnimalType\":    \"animal_type\",\n",
    "    \"Animal_Type\":   \"animal_type\",\n",
    "    \"Type\":          \"animal_type\",\n",
    "    # Breed\n",
    "    \"PrimaryBreed\":  \"breed\",\n",
    "    \"Animal_Breed\":  \"breed\",\n",
    "    \"Breed\":         \"breed\",\n",
    "    # Color\n",
    "    \"PrimaryColor\":  \"primary_color\",\n",
    "    \"Color\":         \"primary_color\",\n",
    "    # Age\n",
    "    \"Age\":           \"age\",\n",
    "    # Date of Birth\n",
    "    \"Date Of Birth\":   \"date_of_birth\",\n",
    "    # Sex\n",
    "    \"Sex\":           \"sex\",\n",
    "    # Intake fields\n",
    "    \"IntakeType\":        \"intake_type\",\n",
    "    \"Intake_type\":       \"intake_type\",\n",
    "    \"Intake Type\":       \"intake_type\",\n",
    "    \"IntakeCondition\":   \"intake_condition\",\n",
    "    \"Intake_Condition\":  \"intake_condition\",\n",
    "    \"Intake Condition\":  \"intake_condition\",\n",
    "    \"IntakeReason\":      \"intake_reason\",\n",
    "    \"reason\":            \"intake_reason\",\n",
    "    \"IntakeDate\":        \"intake_date\",\n",
    "    \"Intake_Date\":       \"intake_date\",\n",
    "    \"Intake Date\":       \"intake_date\",\n",
    "    # Outcome fields\n",
    "    \"OutcomeType\":       \"outcome_type\",\n",
    "    \"outcome_type\":      \"outcome_type\",\n",
    "    \"Outcome Type\":      \"outcome_type\",\n",
    "    \"OutcomeDate\":       \"outcome_date\",\n",
    "    \"Outcome_Date\":      \"outcome_date\",\n",
    "    \"Outcome Date\":      \"outcome_date\",\n",
    "}\n",
    "\n",
    "# Function to apply the column mapping \n",
    "def standardize_columns(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize DataFrame column names.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The raw DataFrame whose columns need standardization to enable better\n",
    "        analysis.\n",
    "    mapping : dict\n",
    "        A dict where keys are original column names (exact match) and\n",
    "        values are the desired standardized names (snake_case).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A copy of `df` with:\n",
    "        1. Columns renamed according to `mapping`.\n",
    "        2. All column names converted to lowercase.\n",
    "        3. Any duplicate column names (arising when multiple originals map\n",
    "           to the same new name) removed—only the first occurrence is kept.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Columns not present in `mapping` are left unchanged (apart from lowercasing).\n",
    "    - Renaming happens before lowercasing, so mapping keys are case-sensitive.\n",
    "    - Dropping duplicate columns avoids collisions in downstream code.\n",
    "    \"\"\"\n",
    "    # Apply the renaming mapping\n",
    "    df = df.rename(columns=mapping)\n",
    "    # Convert all column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Remove duplicate columns, keeping the first occurrence\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    return df\n",
    "\n",
    "# Apply the column mapping to each DataFrame\n",
    "CLEAN_DFS = {\n",
    "    source: standardize_columns(df, COLUMN_MAP)\n",
    "    for source, df in BRONZE_DFS.items()\n",
    "}\n",
    "\n",
    "# Uncomment the following lines to do a quick check\n",
    "# --------------------------------------------------------------\n",
    "# print(\"San Jose columns:\", san_jose_clean.columns.tolist())\n",
    "# print(\"Dallas   columns:\", dallas_clean.columns.tolist())\n",
    "# print(\"SoCo     columns:\", soco_clean.columns.tolist())\n",
    "# --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 4. Data Merging & Harmonization\n",
    "\n",
    "**Purpose:**  \n",
    "Combine the cleaned DataFrames into one Bronze-layer table:  \n",
    "- Tag each row with its source (`san_jose`, `dallas`, or `soco`).  \n",
    "- Reindex to a common `FINAL_COLUMNS` list.  \n",
    "- Drop exact duplicates and enforce correct dtypes.  \n",
    "\n",
    "Result: a single `bronze_df` ready for analysis or Silver-layer transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Bronze shape: (105597, 14)\n",
      "source\n",
      "dallas      65063\n",
      "soco        30550\n",
      "san_jose     9984\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ─── Data Merging ───\n",
    "\n",
    "# Tag each DataFrame with its source to allow for tracking\n",
    "for source, df in CLEAN_DFS.items():\n",
    "    df[\"source\"] = source\n",
    "\n",
    "# Now lets define the final column order for the Bronze Layer\n",
    "FINAL_COLUMNS = [\n",
    "    \"animal_id\",\n",
    "    \"animal_type\",\n",
    "    \"breed\",\n",
    "    \"primary_color\",\n",
    "    \"age\",\n",
    "    \"date_of_birth\",\n",
    "    \"sex\",\n",
    "    \"intake_type\",\n",
    "    \"intake_condition\",\n",
    "    \"intake_reason\",\n",
    "    \"intake_date\",\n",
    "    \"outcome_type\",\n",
    "    \"outcome_date\",\n",
    "    \"source\",\n",
    "]\n",
    "\n",
    "# This is where we will concatenate the DataFrames\n",
    "def merge_bronze(final_cols: list, **dfs: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Stack multiple source DataFrames into a single Bronze DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : one or more pandas.DataFrame\n",
    "        Cleaned DataFrames to merge (must share standardized column names).\n",
    "    final_cols : list of str\n",
    "        Desired column order for the merged Bronze layer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The combined Bronze DataFrame with only `final_cols`, in that order.\n",
    "    \"\"\"\n",
    "    combined = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "    # Keep only the columns we care about in the specified order\n",
    "    combined = combined.reindex(columns=final_cols)\n",
    "    return combined\n",
    "\n",
    "# Merge the DataFrames and drop duplicates\n",
    "bronze_df = merge_bronze(final_cols=FINAL_COLUMNS, **CLEAN_DFS)\n",
    "bronze_df = bronze_df.drop_duplicates()\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"Final Bronze shape:\", bronze_df.shape)\n",
    "print(bronze_df[\"source\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 3. Quick Exploratory Checks\n",
    "\n",
    "**Purpose:**  \n",
    "Perform lightweight diagnostics to understand your data:  \n",
    "- **Missing values:** Where do we need imputation or exclusion?  \n",
    "- **Unique counts:** Which columns are constant vs. highly cardinal?  \n",
    "- **Distributions:** How do key fields like `intake_type` or `outcome_type` break down?  \n",
    "- **Date range:** Are you covering the expected time span?  \n",
    "- **Trends:** Monthly intake counts to spot gaps or seasonality.  \n",
    "\n",
    "Use these insights to guide further cleaning or deeper EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "animal_id                0\n",
      "animal_type              0\n",
      "breed                   39\n",
      "primary_color        65063\n",
      "age                  95613\n",
      "date_of_birth        82476\n",
      "sex                  65063\n",
      "intake_type              0\n",
      "intake_condition         0\n",
      "intake_reason       105140\n",
      "intake_date              0\n",
      "outcome_type           371\n",
      "outcome_date          1448\n",
      "source                   0\n",
      "dtype: int64 \n",
      "\n",
      "Unique values per column:\n",
      "animal_id           85432\n",
      "animal_type             6\n",
      "breed                1221\n",
      "primary_color         394\n",
      "age                    61\n",
      "date_of_birth        6572\n",
      "sex                    10\n",
      "intake_type            23\n",
      "intake_condition       26\n",
      "intake_reason          25\n",
      "intake_date          3983\n",
      "outcome_type           29\n",
      "outcome_date         3597\n",
      "source                  3\n",
      "dtype: int64 \n",
      "\n",
      "Outcome types (%):\n",
      "outcome_type\n",
      "ADOPTION             28.6%\n",
      "TRANSFER             14.8%\n",
      "FOSTER               11.7%\n",
      "RETURN TO OWNER       9.6%\n",
      "EUTHANIZED            8.2%\n",
      "RETURNED TO OWNER     5.2%\n",
      "EUTHANIZE             4.0%\n",
      "LOST EXP              3.2%\n",
      "TREATMENT             2.1%\n",
      "DISPOSAL              1.9%\n",
      "TNR                   1.8%\n",
      "DIED                  1.4%\n",
      "FOUND EXP             1.4%\n",
      "CLOSED                1.0%\n",
      "RTF                   1.0%\n",
      "OTHER                 0.9%\n",
      "EUTH                  0.7%\n",
      "RTO                   0.7%\n",
      "RESCUE                0.6%\n",
      "WILDLIFE              0.5%\n",
      "FOUND ANIM            0.2%\n",
      "MISSING               0.2%\n",
      "SNR                   0.1%\n",
      "RTOS                  0.1%\n",
      "VET                   0.0%\n",
      "ESCAPED/STOLEN        0.0%\n",
      "REQ EUTH              0.0%\n",
      "NEUTER                0.0%\n",
      "SPAY                  0.0%\n",
      "Name: proportion, dtype: object \n",
      "\n",
      "Intake types (%):\n",
      "intake_type\n",
      "STRAY              57.0%\n",
      "FOSTER             12.0%\n",
      "OWNER SURRENDER    11.9%\n",
      "CONFISCATED         3.8%\n",
      "CONFISCATE          2.8%\n",
      "TNR                 2.2%\n",
      "TREATMENT           2.1%\n",
      "WILDLIFE            1.7%\n",
      "DISPO REQ           1.2%\n",
      "RESOURCE            1.1%\n",
      "QUARANTINE          1.0%\n",
      "KEEPSAFE            0.8%\n",
      "TRANSFER            0.7%\n",
      "ADOPTION RETURN     0.5%\n",
      "S/N CLINIC          0.4%\n",
      "OWNER SUR           0.3%\n",
      "RETURN              0.2%\n",
      "BORN HERE           0.1%\n",
      "DISPOS REQ          0.1%\n",
      "OS APPT             0.0%\n",
      "EUTH REQ            0.0%\n",
      "SPAY                0.0%\n",
      "NEUTER              0.0%\n",
      "Name: proportion, dtype: object \n",
      "\n",
      "Intake date range: 2013-08-16 to 2025-09-27 \n",
      "\n",
      "Age summary:\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: age_num, dtype: float64 \n",
      "\n",
      "Monthly intake counts by source:\n",
      "source      dallas  san_jose  soco\n",
      "year_month                        \n",
      "2025-02       2434       153   160\n",
      "2025-03       3017       136   149\n",
      "2025-04       3114        95   275\n",
      "2025-05       1927        65   181\n",
      "2025-09          1         0     0\n"
     ]
    }
   ],
   "source": [
    "# ─── Step 6: Quick Exploratory Checks ───\n",
    "\n",
    "# Missing values per column\n",
    "print(\"Missing values:\")\n",
    "print(bronze_df.isna().sum(), \"\\n\")\n",
    "\n",
    "# Cardinality (distinct counts)\n",
    "print(\"Unique values per column:\")\n",
    "print(bronze_df.nunique(), \"\\n\")\n",
    "\n",
    "# Outcome‐type distribution\n",
    "print(\"Outcome types (%):\")\n",
    "print(bronze_df[\"outcome_type\"]\n",
    "      .value_counts(normalize=True)\n",
    "      .mul(100)\n",
    "      .round(1)\n",
    "      .astype(str) + \"%\", \"\\n\")\n",
    "\n",
    "# Intake‐type distribution\n",
    "print(\"Intake types (%):\")\n",
    "print(bronze_df[\"intake_type\"]\n",
    "      .value_counts(normalize=True)\n",
    "      .mul(100)\n",
    "      .round(1)\n",
    "      .astype(str) + \"%\", \"\\n\")\n",
    "\n",
    "# Time span of intake dates\n",
    "print(\"Intake date range:\",\n",
    "      bronze_df[\"intake_date\"].min().date(),\n",
    "      \"to\",\n",
    "      bronze_df[\"intake_date\"].max().date(),\n",
    "      \"\\n\")\n",
    "\n",
    "# Age summary (if numeric)\n",
    "if \"age\" in bronze_df.columns:\n",
    "    # coerce to numeric (some age values may be strings)\n",
    "    bronze_df[\"age_num\"] = pd.to_numeric(bronze_df[\"age\"], errors=\"coerce\")\n",
    "    print(\"Age summary:\")\n",
    "    print(bronze_df[\"age_num\"].describe(), \"\\n\")\n",
    "\n",
    "#Monthly counts by source (to check seasonality or data gaps)\n",
    "bronze_df[\"year_month\"] = bronze_df[\"intake_date\"].dt.to_period(\"M\")\n",
    "monthly_counts = (\n",
    "    bronze_df\n",
    "    .groupby([\"year_month\", \"source\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "print(\"Monthly intake counts by source:\")\n",
    "print(monthly_counts.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
