{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silver Data Cleaning\n",
    "\n",
    "**Purpose:** Clean raw data from the [Bronze](./1_bronze.ipynb) layer to create a unified data asset. This includes column standardization, data type enforcement, value harmonization, deduplication, and provenance tracking.\n",
    "\n",
    "**Transformations Applied:**\n",
    "- **Standardize** column names to lowercase snake_case\n",
    "- **Tag** each row with its source region for provenance\n",
    "- **Harmonize** categorical values across data sources\n",
    "- **Enforce** consistent data types\n",
    "\n",
    "This data will be used when creating [Gold](./3_gold.ipynb), where tailored data assets will be created to efficiently answer specific questions.\n",
    "\n",
    "\n",
    "For more on Medallion Architecture, see [Databricks Glossary: Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture) (Databricks, n.d.).\n",
    "\n",
    "---\n",
    "\n",
    "### References  \n",
    "Databricks. (n.d.). *Medallion Architecture*. Retrieved May 10, 2025, from https://www.databricks.com/glossary/medallion-architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "TBD... Planned to reorganize once finalized changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "**Purpose:**  \n",
    "Ensure the environment has all necessary libraries installed and imported.  \n",
    "- `%pip install -r ../../requirements.txt` installs dependencies. \n",
    "\n",
    "> **Note:** we use a project-wide `requirements.txt` for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/pip/__main__.py\", line 8, in <module>\n",
      "    if sys.path[0] in (\"\", os.getcwd()):\n",
      "                           ^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Below, we define our Bronze Data Assets, so that we can work with them. We also define maps that will help us process the data and join different dataframes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source configurations\n",
    "BRONZE_DIR = \"../../data-assets/bronze\"\n",
    "BRONZE_FILE_NAME = \"{}_df.parquet\"\n",
    "\n",
    "# Load all the Bronze datasets\n",
    "BRONZE_FILES = [\"dallas\", \"san_jose\", \"soco\"]\n",
    "BRONZE_FILE_PATHS = {\n",
    "    file: os.path.join(BRONZE_DIR, BRONZE_FILE_NAME.format(file)) for file in BRONZE_FILES \n",
    "}\n",
    "BRONZE_DFS = {\n",
    "    file: pd.read_parquet(path) for file, path in BRONZE_FILE_PATHS.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Standardization\n",
    "\n",
    "**Purpose:**  \n",
    "Clean up and harmonize column names across sources:  \n",
    "- Apply a single `COLUMN_MAP` dict.  \n",
    "- Lowercase everything for consistency.  \n",
    "- Explicitly state column data type\n",
    "- Bucket columns with high caridnaliy `primary_color`.\n",
    "- Create an `age_category` which will bucket each species based on matrurity level.\n",
    "- Standardize epxlicit naming conventons to create usable data points for analysis.\n",
    "- Drop unintended duplicates.  \n",
    "\n",
    "This ensures downstream steps can assume a uniform schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Data Cleaning ───\n",
    "\n",
    "# Function to apply the column mapping \n",
    "def standardize_columns(source: str, df: pd.DataFrame, mapping: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize DataFrame column names.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The raw DataFrame whose columns need standardization to enable better\n",
    "        analysis.\n",
    "    mapping : dict\n",
    "        A dict where keys are original column names (exact match) and\n",
    "        values are the desired standardized names (snake_case).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A copy of `df` with:\n",
    "        1. Columns renamed according to `mapping`.\n",
    "        2. All column names converted to lowercase.\n",
    "        3. Any duplicate column names (arising when multiple originals map\n",
    "           to the same new name) removed—only the first occurrence is kept.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Columns not present in `mapping` are left unchanged (apart from lowercasing).\n",
    "    - Renaming happens before lowercasing, so mapping keys are case-sensitive.\n",
    "    - Dropping duplicate columns avoids collisions in downstream code.\n",
    "    \"\"\"\n",
    "    # Apply the renaming mapping\n",
    "    df = df.rename(columns=mapping)\n",
    "    # Convert all column names to lowercase\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Remove duplicate columns, keeping the first occurrence\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    print(f\" - {source}: {list(df.columns)}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will define the full column mapping for all the DataFrames:\n",
    "COLUMN_MAP = {\n",
    "    # Animal identification\n",
    "    **{col: \"animal_id\" for col in [\"AnimalID\", \"Animal_Id\", \"Animal ID\"]}, # Using Python's dictionary operators for cleaner code!\n",
    "    **{col: \"animal_type\" for col in [\"AnimalType\", \"Animal_Type\", \"Type\"]},\n",
    "    \n",
    "    # Animal characteristics\n",
    "    **{col: \"breed\" for col in [\"PrimaryBreed\", \"Animal_Breed\", \"Breed\"]},\n",
    "    **{col: \"primary_color\" for col in [\"PrimaryColor\", \"Color\"]},\n",
    "    \"Age\": \"age\",\n",
    "    \"Date Of Birth\": \"date_of_birth\",\n",
    "    \"Sex\": \"sex\",\n",
    "    \n",
    "    # Intake information\n",
    "    **{col: \"intake_type\" for col in [\"IntakeType\", \"Intake_type\", \"Intake Type\"]},\n",
    "    **{col: \"intake_condition\" for col in [\"IntakeCondition\", \"Intake_Condition\", \"Intake Condition\"]},\n",
    "    **{col: \"intake_reason\" for col in [\"IntakeReason\", \"Reason\"]},\n",
    "    **{col: \"intake_date\" for col in [\"IntakeDate\", \"Intake_Date\", \"Intake Date\"]},\n",
    "    \n",
    "    # Outcome information\n",
    "    **{col: \"outcome_type\" for col in [\"OutcomeType\", \"outcome_type\", \"Outcome Type\"]},\n",
    "    **{col: \"outcome_date\" for col in [\"OutcomeDate\", \"Outcome_Date\", \"Outcome Date\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column standardization starting...\n",
      "\n",
      " - dallas: ['animal_id', 'animal_type', 'breed', 'kennel_number', 'kennel_status', 'tag_type', 'activity_number', 'activity_sequence', 'source_id', 'census_tract', 'council_district', 'intake_type', 'intake_subtype', 'intake_total', 'intake_reason', 'staff_id', 'intake_date', 'intake_time', 'due_out', 'intake_condition', 'hold_request', 'outcome_type', 'outcome_subtype', 'outcome_date', 'outcome_time', 'receipt_number', 'impound_number', 'service_request_number', 'outcome_condition', 'chip_status', 'animal_origin', 'additional_information', 'month', 'year']\n",
      " - san_jose: ['_id', 'animal_id', 'animalname', 'animal_type', 'primary_color', 'secondarycolor', 'breed', 'sex', 'dob', 'age', 'intake_date', 'intake_condition', 'intake_type', 'intakesubtype', 'intake_reason', 'outcome_date', 'outcome_type', 'outcomesubtype', 'outcomecondition', 'crossing', 'jurisdiction', 'lastupdate']\n",
      " - soco: ['name', 'animal_type', 'breed', 'primary_color', 'sex', 'size', 'date_of_birth', 'impound number', 'kennel number', 'animal_id', 'intake_date', 'outcome_date', 'days in shelter', 'intake_type', 'intake subtype', 'outcome_type', 'outcome subtype', 'intake_condition', 'outcome condition', 'intake jurisdiction', 'outcome jurisdiction', 'outcome zip code', 'location', 'count']\n",
      "\n",
      "---\n",
      "Column standardization complete.\n"
     ]
    }
   ],
   "source": [
    "# Apply standardization (renaming and lowercasing) to all DataFrames\n",
    "print(\"Column standardization starting...\\n\")\n",
    "CLEAN_DFS = {\n",
    "    source: standardize_columns(source, df, COLUMN_MAP)\n",
    "    for source, df in BRONZE_DFS.items()\n",
    "}\n",
    "print(\"\\n---\\nColumn standardization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type Enforcement & Value Harmonization\n",
    "\n",
    "Apply consistent data types and standardize categorical values across sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── SILVER DTYPE MAPPING ───\n",
    "# @Lina Add in your explicit dtypes here \n",
    "SILVER_DTYPES = {\n",
    "    'intake_type'     : 'category',\n",
    "    'intake_condition': 'category',\n",
    "    'intake_reason'   : 'object',\n",
    "    'intake_date'     : 'datetime64[ns]',\n",
    "    'outcome_type'    : 'category',\n",
    "    'outcome_date'    : 'datetime64[ns]',\n",
    "}\n",
    "\n",
    "VALUE_MAPPINGS = {\n",
    "\n",
    "    # @ Lina do your bucketing in here\n",
    "\n",
    "    # ==== INTAKE TYPE ====\n",
    "\n",
    "    'intake_type': {\n",
    "    # Born at facility\n",
    "    \"BORN HERE\"           : \"born_at_shelter\",    # SO\n",
    "    # Confiscated/Legal\n",
    "    \"CONFISCATE\"          : \"confiscated\",        # SJ, SO\n",
    "    \"CONFISCATED\"         : \"confiscated\",        # DA\n",
    "    # Disposal/Euthanasia requests\n",
    "    \"DISPO REQ\"           : \"disposal_request\",   # SJ\n",
    "    \"DISPOS REQ\"          : \"disposal_request\",   # DA\n",
    "    \"EUTH REQ\"            : \"euthanasia_request\", # SJ\n",
    "    # Foster\n",
    "    \"FOSTER\"              : \"foster\",             # DA, SJ\n",
    "    # Protective custody/Quarantine\n",
    "    \"KEEPSAFE\"            : \"protective_custody\", # DA\n",
    "    \"QUARANTINE\"          : \"protective_custody\", # SO\n",
    "    # Resource/Treatment\n",
    "    \"RESOURCE\"            : \"treatment\",          # DA\n",
    "    \"TREATMENT\"           : \"treatment\",          # DA\n",
    "    # Return to owner\n",
    "    \"RETURN\"              : \"return_to_owner\",    # SJ\n",
    "    # Spay/Neuter services\n",
    "    \"NEUTER\"              : \"spay_neuter\",        # SJ\n",
    "    \"S/N CLINIC\"          : \"spay_neuter\",        # SJ\n",
    "    \"SPAY\"                : \"spay_neuter\",        # SJ\n",
    "    # Stray/TNR\n",
    "    \"STRAY\"               : \"stray\",              # DA, SJ, SO\n",
    "    \"TNR\"                 : \"stray\",              # DA\n",
    "    # Surrender/Returns\n",
    "    \"ADOPTION RETURN\"     : \"surrender\",          # SO\n",
    "    \"OS APPT\"             : \"surrender\",          # SO\n",
    "    \"OWNER SUR\"           : \"surrender\",          # SJ\n",
    "    \"OWNER SURRENDER\"     : \"surrender\",          # DA, SO\n",
    "    # Transfer\n",
    "    \"TRANSFER\"            : \"transfer\",           # DA, SJ, SO\n",
    "    # Wildlife\n",
    "    \"WILDLIFE\"            : \"wildlife\"            # DA, SJ\n",
    "    },\n",
    "    \n",
    "    # ==== INTAKE CONDITION ====\n",
    "\n",
    "    'intake_condition': {\n",
    "    # Age-related\n",
    "    \"GERIATRIC\"           : \"age_related\",        # DA\n",
    "    \"UNDERAGE\"            : \"age_related\",        # DA\n",
    "    # Behavioral\n",
    "    \"AGGRESSIVE\"          : \"behavioral\",         # SJ\n",
    "    \"BEH M\"               : \"behavioral\",         # SJ\n",
    "    \"BEH R\"               : \"behavioral\",         # SJ\n",
    "    \"BEH U\"               : \"behavioral\",         # SJ\n",
    "    \"FERAL\"               : \"behavioral\",         # SJ\n",
    "    # Critical/Severe\n",
    "    \"CRITICAL\"            : \"critical\",           # DA\n",
    "    \"FATAL\"               : \"critical\",           # DA\n",
    "    \"UNTREATABLE\"         : \"critical\",           # SC\n",
    "    # Deceased\n",
    "    \"DECEASED\"            : \"deceased\",           # DA\n",
    "    \"DEAD\"                : \"deceased\",           # SJ\n",
    "    # Healthy/Normal\n",
    "    \"APP WNL\"             : \"healthy\",            # DA\n",
    "    \"NORMAL\"              : \"healthy\",            # DA\n",
    "    \"HEALTHY\"             : \"healthy\",            # SJ/SC\n",
    "    # Medical\n",
    "    \"APP INJ\"             : \"medical\",            # DA\n",
    "    \"APP SICK\"            : \"medical\",            # DA\n",
    "    \"MED EMERG\"           : \"medical\",            # SJ\n",
    "    \"MED M\"               : \"medical\",            # SJ\n",
    "    \"MED R\"               : \"medical\",            # SJ\n",
    "    \"MED SEV\"             : \"medical\",            # SJ\n",
    "    \"TREATABLE/MANAGEABLE\": \"medical\",            # SC\n",
    "    \"TREATABLE/REHAB\"     : \"medical\",            # SC\n",
    "    # Reproductive\n",
    "    \"NURSING\"             : \"reproductive\",       # SJ\n",
    "    \"PREGNANT\"            : \"reproductive\",       # SJ\n",
    "    # Unknown/Other\n",
    "    \"UNKNOWN\"             : \"unknown\"             # SC\n",
    "    },\n",
    "    \n",
    "    # ==== INTAKE REASON ====\n",
    "\n",
    "    'intake_reason': {\n",
    "    # Adoption related\n",
    "    \"FOR ADOPT\"           : \"for_adoption\",       # DA\n",
    "    \"FOR PLCMNT\"          : \"for_adoption\",       # DA\n",
    "    \"IP ADOPT\"            : \"for_adoption\",       # SJ\n",
    "    # Behavioral issues\n",
    "    \"BEHAVIOR\"            : \"behavior\",           # DA\n",
    "    \"AGG ANIMAL\"          : \"behavior\",           # SJ\n",
    "    \"AGG PEOPLE\"          : \"behavior\",           # SJ\n",
    "    \"BITES\"               : \"behavior\",           # SJ\n",
    "    \"CHASES ANI\"          : \"behavior\",           # SJ\n",
    "    \"DESTRUC IN\"          : \"behavior\",           # SJ\n",
    "    \"ESCAPES\"             : \"behavior\",           # SJ\n",
    "    \"HOUSE SOIL\"          : \"behavior\",           # SJ\n",
    "    \"HYPER\"               : \"behavior\",           # SJ\n",
    "    \"NOFRIENDLY\"          : \"behavior\",           # SJ\n",
    "    \"PICA\"                : \"behavior\",           # SJ\n",
    "    # Breeding restrictions\n",
    "    \"BREED REST\"          : \"breed_restriction\",  # DA\n",
    "    # Euthanasia/Death\n",
    "    \"OWR REQ EU\"          : \"owner_requested_euthanasia\", # DA\n",
    "    \"IP EUTH\"             : \"owner_requested_euthanasia\", # SJ\n",
    "    # Medical\n",
    "    \"MEDICAL\"             : \"medical\",            # DA\n",
    "    \"SURGERY\"             : \"medical\",            # DA\n",
    "    \"VET CARE\"            : \"medical\",            # DA\n",
    "    # Other/Miscellaneous\n",
    "    \"OTHER\"               : \"other\",              # DA\n",
    "    \"OTHRINTAKS\"          : \"other\",              # DA\n",
    "    # Owner surrender - Housing/Financial\n",
    "    \"CANTAFFORD\"          : \"owner_surrender\",    # DA\n",
    "    \"EVICTION\"            : \"owner_surrender\",    # DA\n",
    "    \"FINANCIAL\"           : \"owner_surrender\",    # DA\n",
    "    \"HOUSING\"             : \"owner_surrender\",    # DA\n",
    "    \"LLCONFLICT\"          : \"owner_surrender\",    # DA\n",
    "    \"LOSSHOUSNG\"          : \"owner_surrender\",    # DA\n",
    "    \"PETDEPFEE\"           : \"owner_surrender\",    # DA\n",
    "    \"LANDLORD\"            : \"owner_surrender\",    # SJ\n",
    "    \"MOVE\"                : \"owner_surrender\",    # SJ\n",
    "    \"NO HOME\"             : \"owner_surrender\",    # SJ\n",
    "    # Owner surrender - Personal/Life circumstances\n",
    "    \"OWR DEATH\"           : \"owner_surrender\",    # DA\n",
    "    \"PERLIFECNG\"          : \"owner_surrender\",    # DA\n",
    "    \"PERSNLISSU\"          : \"owner_surrender\",    # DA\n",
    "    \"TEMLIFECNG\"          : \"owner_surrender\",    # DA\n",
    "    \"ALLERGIC\"            : \"owner_surrender\",    # SJ\n",
    "    \"CHILD PROB\"          : \"owner_surrender\",    # SJ\n",
    "    \"NO TIME\"             : \"owner_surrender\",    # SJ\n",
    "    \"OWNER DIED\"          : \"owner_surrender\",    # SJ\n",
    "    \"OWNER PROB\"          : \"owner_surrender\",    # SJ\n",
    "    \"TRAVEL\"              : \"owner_surrender\",    # SJ\n",
    "    # Owner surrender - Pet management\n",
    "    \"NOTRIGHTFT\"          : \"owner_surrender\",    # DA\n",
    "    \"ATTENTION\"           : \"owner_surrender\",    # SJ\n",
    "    \"OTHER PET\"           : \"owner_surrender\",    # SJ\n",
    "    \"TOO BIG\"             : \"owner_surrender\",    # SJ\n",
    "    \"TOO MANY\"            : \"owner_surrender\",    # SJ\n",
    "    # Stray/Found\n",
    "    \"STRAY\"               : \"stray\",              # DA\n",
    "    # Temporary/Short-term\n",
    "    \"SHORT-TERM\"          : \"temporary_care\",     # DA\n",
    "    # TNR/Clinic\n",
    "    \"TNR CLINIC\"          : \"trap_neuter_return\", # DA\n",
    "    # Transfers\n",
    "    \"TRANSFER\"            : \"transfer\"            # DA\n",
    "},\n",
    "\n",
    "    # ==== OUTCOME TYPE ====\n",
    "    \n",
    "    'outcome_type': {\n",
    "    # Adoption & Rescue\n",
    "    \"ADOPTION\"            : \"adoption\",           # DA, SJ, SO\n",
    "    \"RESCUE\"              : \"adoption\",           # SJ\n",
    "    # Death/Euthanasia\n",
    "    \"DIED\"                : \"deceased\",           # DA, SJ, SO\n",
    "    \"EUTH\"                : \"euthanasia\",         # SJ\n",
    "    \"EUTHANIZE\"           : \"euthanasia\",         # SO\n",
    "    \"EUTHANIZED\"          : \"euthanasia\",         # DA\n",
    "    \"REQ EUTH\"            : \"euthanasia\",         # SJ\n",
    "    # Disposal/Other deaths\n",
    "    \"DISPOSAL\"            : \"disposal\",           # DA, SJ, SO\n",
    "    # Escaped/Missing/Lost\n",
    "    \"ESCAPED/STOLEN\"      : \"escaped\",            # SO\n",
    "    \"FOUND ANIM\"          : \"found\",              # SJ\n",
    "    \"FOUND EXP\"           : \"found\",              # DA\n",
    "    \"LOST EXP\"            : \"lost\",               # DA, SJ\n",
    "    \"MISSING\"             : \"lost\",               # DA, SJ\n",
    "    # Foster\n",
    "    \"FOSTER\"              : \"foster\",             # DA, SJ\n",
    "    # Medical/Treatment\n",
    "    \"TREATMENT\"           : \"treatment\",          # DA\n",
    "    \"VET\"                 : \"treatment\",          # SO\n",
    "    # Other/Closed/Unknown\n",
    "    \"CLOSED\"              : \"other\",              # DA\n",
    "    \"OTHER\"               : \"other\",              # DA\n",
    "    # Return to Owner\n",
    "    \"RETURN TO OWNER\"     : \"return_to_owner\",    # SO\n",
    "    \"RETURNED TO OWNER\"   : \"return_to_owner\",    # DA\n",
    "    \"RTF\"                 : \"return_to_field\",    # SJ\n",
    "    \"RTO\"                 : \"return_to_owner\",    # SJ\n",
    "    \"RTOS\"                : \"return_to_owner\",    # SO\n",
    "    # Spay/Neuter Services\n",
    "    \"NEUTER\"              : \"spay_neuter\",        # SJ\n",
    "    \"SNR\"                 : \"spay_neuter\",        # DA\n",
    "    \"SPAY\"                : \"spay_neuter\",        # SJ\n",
    "    # TNR/Release\n",
    "    \"TNR\"                 : \"trap_nueter_release\",# DA\n",
    "    # Transfer\n",
    "    \"TRANSFER\"            : \"transfer\",           # DA, SJ, SO\n",
    "    # Wildlife\n",
    "    \"WILDLIFE\"            : \"wildlife\"            # DA\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:** The cell below reveals inconsistencies across datasets where identical concepts are represented with slight variations (Example: \"CONFISCATED\", \"CONFISCATE\", \"CONFISCTED\"). These inconsistencies would create data fragmentation in downstream analysis.\n",
    "\n",
    "The `apply_silver_transforms` function addresses these issues by:\n",
    "\n",
    "1. **Enforcing uniform data types** across all datasets\n",
    "2. **Standardizing categorical values** using the VALUE_MAPPINGS dictionary\n",
    "3. **Validating temporal data** and handling future dates\n",
    "4. **Gracefully handling missing columns** across different data sources\n",
    "\n",
    "This ensures all datasets share a common vocabulary and data structure for reliable analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VALUE HARMONIZATION: BEFORE vs AFTER\n",
      "================================================================================\n",
      "\n",
      "DALLAS DATASET:\n",
      "   BEFORE intake_type: ['CONFISCATED', 'DISPOS REQ', 'FOSTER', 'KEEPSAFE', 'OWNER SURRENDER', 'RESOURCE', 'STRAY', 'TNR', 'TRANSFER', 'TREATMENT', 'WILDLIFE']\n",
      "   BEFORE intake_condition: ['APP INJ', 'APP SICK', 'APP WNL', 'CRITICAL', 'DECEASED', 'FATAL', 'GERIATRIC', 'NORMAL', 'UNDERAGE']\n",
      "   BEFORE intake_reason: ['BEHAVIOR', 'BREED REST', 'CANTAFFORD', 'EVICTION', 'FINANCIAL', 'FOR ADOPT', 'FOR PLCMNT', 'HOUSING', 'LLCONFLICT', 'LOSSHOUSNG', 'MEDICAL', 'NOTRIGHTFT', 'OTHER', 'OTHRINTAKS', 'OWR DEATH', 'OWR REQ EU', 'PERLIFECNG', 'PERSNLISSU', 'PETDEPFEE', 'SHORT-TERM', 'STRAY', 'SURGERY', 'TEMLIFECNG', 'TNR CLINIC', 'TRANSFER', 'VET CARE']\n",
      "   BEFORE outcome_type: ['ADOPTION', 'CLOSED', 'DIED', 'DISPOSAL', 'EUTHANIZED', 'FOSTER', 'FOUND EXP', 'LOST EXP', 'MISSING', 'OTHER', 'RETURNED TO OWNER', 'SNR', 'TNR', 'TRANSFER', 'TREATMENT', 'WILDLIFE']\n",
      "\n",
      "SAN_JOSE DATASET:\n",
      "   BEFORE intake_type: ['CONFISCATE', 'DISPO REQ', 'EUTH REQ', 'FOSTER', 'NEUTER', 'OWNER SUR', 'RETURN', 'S/N CLINIC', 'SPAY', 'STRAY', 'TRANSFER', 'WILDLIFE']\n",
      "   BEFORE intake_condition: ['AGGRESSIVE', 'BEH M', 'BEH R', 'BEH U', 'DEAD', 'FERAL', 'HEALTHY', 'MED EMERG', 'MED M', 'MED R', 'MED SEV', 'NURSING', 'PREGNANT']\n",
      "   BEFORE intake_reason: ['AGG ANIMAL', 'AGG PEOPLE', 'ALLERGIC', 'ATTENTION', 'BITES', 'CHASES ANI', 'CHILD PROB', 'DESTRUC IN', 'ESCAPES', 'EUTH BEHAV', 'HOUSE SOIL', 'HYPER', 'IP ADOPT', 'IP EUTH', 'LANDLORD', 'MOVE', 'NO HOME', 'NO TIME', 'NOFRIENDLY', 'OTHER PET', 'OWNER DIED', 'OWNER PROB', 'PICA', 'RESPONSIBL', 'TOO BIG', 'TOO MANY', 'TRAVEL']\n",
      "   BEFORE outcome_type: ['ADOPTION', 'DIED', 'DISPOSAL', 'EUTH', 'FOSTER', 'FOUND ANIM', 'LOST EXP', 'MISSING', 'NEUTER', 'REQ EUTH', 'RESCUE', 'RTF', 'RTO', 'SPAY', 'TRANSFER']\n",
      "\n",
      "SOCO DATASET:\n",
      "   BEFORE intake_type: ['ADOPTION RETURN', 'BORN HERE', 'CONFISCATE', 'OS APPT', 'OWNER SURRENDER', 'QUARANTINE', 'STRAY', 'TRANSFER']\n",
      "   BEFORE intake_condition: ['HEALTHY', 'TREATABLE/MANAGEABLE', 'TREATABLE/REHAB', 'UNKNOWN', 'UNTREATABLE']\n",
      "   BEFORE outcome_type: ['ADOPTION', 'DIED', 'DISPOSAL', 'ESCAPED/STOLEN', 'EUTHANIZE', 'RETURN TO OWNER', 'RTOS', 'TRANSFER', 'VET']\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"VALUE HARMONIZATION: BEFORE vs AFTER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "categorical_cols = ['intake_type', 'intake_condition', 'intake_reason', 'outcome_type']\n",
    "\n",
    "for source, df in CLEAN_DFS.items():\n",
    "    print(f\"\\n{source.upper()} DATASET:\")\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            unique_values = df[col].dropna().unique()\n",
    "            print(f\"   BEFORE {col}: {sorted(unique_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 4. Data Merging & Harmonization\n",
    "\n",
    "**Purpose:**  \n",
    "Stack our fully-cleaned “Silver” tables into one master table, ensure a consistent column order, and tag each row with its region. The result is a single `silver_df` ready for analysis.\n",
    "- Reindex to a common `FINAL_COLUMNS` list.  \n",
    "- Ensure correct dtypes\n",
    "- Bucket like values to reduce dimensionality\n",
    "\n",
    "Result: a single `silver_df` ready for analysis or Gold-layer transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_silver_transforms(df: pd.DataFrame, source: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply comprehensive silver-layer transformations to a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame with standardized columns\n",
    "    source : str\n",
    "        Source identifier for provenance tracking\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Transformed DataFrame with harmonized values and proper types\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Add provenance\n",
    "    df['region'] = source\n",
    "    \n",
    "    # Ensure intake_reason column exists\n",
    "    if 'intake_reason' not in df.columns:\n",
    "        df['intake_reason'] = pd.NA\n",
    "    \n",
    "    # Apply data types\n",
    "    for col, dtype in SILVER_DTYPES.items():\n",
    "        if col in df.columns:\n",
    "            if dtype == 'datetime64[ns]':\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            else:\n",
    "                df[col] = df[col].astype(dtype)\n",
    "    \n",
    "    # Data validation: Check for future dates\n",
    "    current_date = pd.Timestamp.now().normalize()\n",
    "    date_columns = ['intake_date', 'outcome_date']\n",
    "    \n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            future_dates = df[col] > current_date\n",
    "            if future_dates.any():\n",
    "                future_count = future_dates.sum()\n",
    "                max_future_date = df.loc[future_dates, col].max()\n",
    "                print(f\"WARNING: Found {future_count:,} future dates in {col} for {source}\")\n",
    "                print(f\"         Latest future date: {max_future_date.date()}\")\n",
    "                print(f\"         Setting future dates to NaT (Not a Time)\")\n",
    "                \n",
    "                # Set future dates to NaT\n",
    "                df.loc[future_dates, col] = pd.NaT\n",
    "    \n",
    "    # Harmonize categorical values\n",
    "    for col, mapping in VALUE_MAPPINGS.items():\n",
    "        if col in df.columns:\n",
    "            # Normalize text before mapping\n",
    "            normalized = df[col].astype(str).str.strip().str.upper()\n",
    "            df[col] = normalized.map(mapping).fillna('other' if col != 'intake_reason' else 'unknown')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Found 1 future dates in intake_date for dallas\n",
      "         Latest future date: 2025-09-27\n",
      "         Setting future dates to NaT (Not a Time)\n",
      "Silver transformations applied successfully!\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations\n",
    "SILVER_DFS = {\n",
    "    source: apply_silver_transforms(df, source)\n",
    "    for source, df in CLEAN_DFS.items()\n",
    "}\n",
    "\n",
    "print(\"Silver transformations applied successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "AFTER VALUE HARMONIZATION:\n",
      "--------------------------------------------------\n",
      "\n",
      "DALLAS DATASET:\n",
      "   AFTER: intake_type: ['confiscated', 'disposal_request', 'foster', 'protective_custody', 'stray', 'surrender', 'transfer', 'treatment', 'wildlife']\n",
      "   AFTER: intake_condition: ['age_related', 'critical', 'deceased', 'healthy', 'medical']\n",
      "   AFTER: intake_reason: ['behavior', 'breed_restriction', 'for_adoption', 'medical', 'other', 'owner_requested_euthanasia', 'owner_surrender', 'stray', 'temporary_care', 'transfer', 'trap_neuter_return', 'unknown']\n",
      "   AFTER: outcome_type: ['adoption', 'deceased', 'disposal', 'euthanasia', 'foster', 'found', 'lost', 'other', 'return_to_owner', 'spay_neuter', 'transfer', 'trap_nueter_release', 'treatment', 'wildlife']\n",
      "\n",
      "SAN_JOSE DATASET:\n",
      "   AFTER: intake_type: ['confiscated', 'disposal_request', 'euthanasia_request', 'foster', 'return_to_owner', 'spay_neuter', 'stray', 'surrender', 'transfer', 'wildlife']\n",
      "   AFTER: intake_condition: ['behavioral', 'deceased', 'healthy', 'medical', 'reproductive']\n",
      "   AFTER: intake_reason: ['behavior', 'for_adoption', 'owner_requested_euthanasia', 'owner_surrender', 'unknown']\n",
      "   AFTER: outcome_type: ['adoption', 'deceased', 'disposal', 'euthanasia', 'foster', 'found', 'lost', 'other', 'return_to_field', 'return_to_owner', 'spay_neuter', 'transfer']\n",
      "\n",
      "SOCO DATASET:\n",
      "   AFTER: intake_type: ['born_at_shelter', 'confiscated', 'protective_custody', 'stray', 'surrender', 'transfer']\n",
      "   AFTER: intake_condition: ['critical', 'healthy', 'medical', 'unknown']\n",
      "   AFTER: intake_reason: ['unknown']\n",
      "   AFTER: outcome_type: ['adoption', 'deceased', 'disposal', 'escaped', 'euthanasia', 'other', 'return_to_owner', 'transfer', 'treatment']\n",
      "\n",
      "VALUE HARMONIZATION SUMMARY:\n",
      "   - Mapped 4 categorical variables to consistent values\n",
      "   - Unified terminology across Dallas, San Jose, and Sonoma County datasets\n",
      "   - Ready for cross-shelter analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(\"AFTER VALUE HARMONIZATION:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for source, df in SILVER_DFS.items():\n",
    "    print(f\"\\n{source.upper()} DATASET:\")\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            unique_values = df[col].dropna().unique()\n",
    "            print(f\"   AFTER: {col}: {sorted(unique_values)}\")\n",
    "\n",
    "print(f\"\\nVALUE HARMONIZATION SUMMARY:\")\n",
    "print(f\"   - Mapped {len(VALUE_MAPPINGS)} categorical variables to consistent values\")\n",
    "print(f\"   - Unified terminology across Dallas, San Jose, and Sonoma County datasets\")\n",
    "print(f\"   - Ready for cross-shelter analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Integration & Quality Checks\n",
    "\n",
    "Merge all sources into a unified silver dataset and perform quality validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SCHEMA = [\n",
    "    \"animal_id\", \"animal_type\", \"breed\", \"primary_color\", \"age\", \"date_of_birth\", \"sex\",\n",
    "    \"intake_type\", \"intake_condition\", \"intake_reason\", \"intake_date\",\n",
    "    \"outcome_type\", \"outcome_date\", \"region\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_silver_dataset(dataframes: dict[str, pd.DataFrame], schema: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine multiple source DataFrames into unified silver dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframes : dict[str, pd.DataFrame]\n",
    "        Source DataFrames to combine\n",
    "    schema : list[str]\n",
    "        Final column schema to enforce\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Unified silver dataset\n",
    "    \"\"\"\n",
    "    # Combine all sources\n",
    "    combined = pd.concat(dataframes.values(), ignore_index=True, sort=False)\n",
    "    \n",
    "    # Enforce schema\n",
    "    return (\n",
    "        combined\n",
    "        .reindex(columns=schema)\n",
    "        # .drop_duplicates() Dropping duplicates may miss repeat intakes TBD\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver dataset created: 111,907 records × 14 columns\n",
      "Duplicates removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Here we create the final silver dataset\n",
    "silver_df = create_silver_dataset(SILVER_DFS, FINAL_SCHEMA)\n",
    "\n",
    "print(f\"Silver dataset created: {silver_df.shape[0]:,} records × {silver_df.shape[1]} columns\")\n",
    "print(f\"Duplicates removed: {sum(df.shape[0] for df in SILVER_DFS.values()) - silver_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Assessment\n",
    "\n",
    "Comprehensive quality checks and data profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_overview(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Generate comprehensive data quality overview.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataset to profile\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATA QUALITY PROFILE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Dataset overview\n",
    "    print(f\"\\nDATASET OVERVIEW\")\n",
    "    print(f\"Total records: {df.shape[0]:,}\")\n",
    "    print(f\"Total columns: {df.shape[1]}\")\n",
    "    \n",
    "    # Missing data analysis\n",
    "    print(f\"\\nMISSING DATA ANALYSIS\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_pct = (missing_data / len(df) * 100).round(3)\n",
    "    \n",
    "    for col in missing_data.index:\n",
    "        if missing_data[col] > 0:\n",
    "            # change missing_pcft to .4f\n",
    "            print(f\"  {col}: {missing_data[col]:,} ({missing_pct[col]:.3f}%)\")\n",
    "    \n",
    "    # Cardinality analysis\n",
    "    print(f\"\\nCARDINALITY ANALYSIS\")\n",
    "    cardinality = df.nunique().sort_values(ascending=False)\n",
    "    for col, count in cardinality.items():\n",
    "        print(f\"  {col}: {count:,} unique values\")\n",
    "    \n",
    "    # Categorical distributions\n",
    "    categorical_cols = ['intake_type', 'intake_condition', 'intake_reason', 'outcome_type', 'animal_type']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col.upper()} DISTRIBUTION\")\n",
    "            dist = df[col].value_counts(normalize=True).head(10)\n",
    "            for value, pct in dist.items():\n",
    "                print(f\"  {value}: {pct:.1%}\")\n",
    "    \n",
    "    # Temporal analysis\n",
    "    print(f\"\\nTEMPORAL ANALYSIS\")\n",
    "    if 'intake_date' in df.columns:\n",
    "        date_range = df['intake_date'].agg(['min', 'max'])\n",
    "        print(f\"  Intake date range: {date_range['min'].date()} to {date_range['max'].date()}\")\n",
    "        \n",
    "        # Monthly trends\n",
    "        monthly = df.set_index('intake_date').resample('M').size()\n",
    "        print(f\"  Average monthly intake: {monthly.mean():.0f} animals\")\n",
    "        print(f\"  Peak month: {monthly.idxmax().strftime('%B %Y')} ({monthly.max():,} animals)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY PROFILE\n",
      "============================================================\n",
      "\n",
      "DATASET OVERVIEW\n",
      "Total records: 111,907\n",
      "Total columns: 14\n",
      "\n",
      "MISSING DATA ANALYSIS\n",
      "  breed: 39 (0.035%)\n",
      "  primary_color: 65,079 (58.155%)\n",
      "  age: 95,633 (85.458%)\n",
      "  date_of_birth: 88,783 (79.336%)\n",
      "  sex: 65,079 (58.155%)\n",
      "  intake_date: 1 (0.001%)\n",
      "  outcome_date: 2,134 (1.907%)\n",
      "\n",
      "CARDINALITY ANALYSIS\n",
      "  animal_id: 91,523 unique values\n",
      "  date_of_birth: 6,572 unique values\n",
      "  intake_date: 3,984 unique values\n",
      "  outcome_date: 3,599 unique values\n",
      "  breed: 1,235 unique values\n",
      "  primary_color: 395 unique values\n",
      "  age: 64 unique values\n",
      "  outcome_type: 16 unique values\n",
      "  intake_type: 13 unique values\n",
      "  intake_reason: 12 unique values\n",
      "  sex: 10 unique values\n",
      "  intake_condition: 8 unique values\n",
      "  animal_type: 6 unique values\n",
      "  region: 3 unique values\n",
      "\n",
      "INTAKE_TYPE DISTRIBUTION\n",
      "  stray: 59.3%\n",
      "  surrender: 12.1%\n",
      "  foster: 11.4%\n",
      "  confiscated: 6.5%\n",
      "  treatment: 3.0%\n",
      "  disposal_request: 2.2%\n",
      "  wildlife: 1.8%\n",
      "  protective_custody: 1.7%\n",
      "  spay_neuter: 0.9%\n",
      "  transfer: 0.7%\n",
      "\n",
      "INTAKE_CONDITION DISTRIBUTION\n",
      "  healthy: 65.6%\n",
      "  medical: 13.6%\n",
      "  unknown: 10.1%\n",
      "  critical: 3.1%\n",
      "  deceased: 2.8%\n",
      "  age_related: 1.8%\n",
      "  reproductive: 1.6%\n",
      "  behavioral: 1.5%\n",
      "\n",
      "INTAKE_REASON DISTRIBUTION\n",
      "  unknown: 45.8%\n",
      "  other: 29.2%\n",
      "  owner_surrender: 7.0%\n",
      "  medical: 6.1%\n",
      "  for_adoption: 5.7%\n",
      "  stray: 2.5%\n",
      "  transfer: 1.6%\n",
      "  behavior: 1.2%\n",
      "  trap_neuter_return: 0.4%\n",
      "  temporary_care: 0.4%\n",
      "\n",
      "OUTCOME_TYPE DISTRIBUTION\n",
      "  adoption: 28.7%\n",
      "  return_to_owner: 14.9%\n",
      "  transfer: 14.4%\n",
      "  euthanasia: 12.6%\n",
      "  foster: 11.1%\n",
      "  lost: 3.1%\n",
      "  disposal: 2.8%\n",
      "  other: 2.8%\n",
      "  return_to_field: 2.2%\n",
      "  treatment: 2.0%\n",
      "\n",
      "ANIMAL_TYPE DISTRIBUTION\n",
      "  DOG: 56.9%\n",
      "  CAT: 35.0%\n",
      "  OTHER: 3.6%\n",
      "  BIRD: 3.0%\n",
      "  WILDLIFE: 1.4%\n",
      "  LIVESTOCK: 0.0%\n",
      "\n",
      "TEMPORAL ANALYSIS\n",
      "  Intake date range: 2013-08-16 to 2025-05-24\n",
      "  Average monthly intake: 788 animals\n",
      "  Peak month: July 2024 (6,079 animals)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/lrkcgdlx3332x9brp_np1l_c0000gn/T/ipykernel_24033/60873332.py:52: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly = df.set_index('intake_date').resample('M').size()\n"
     ]
    }
   ],
   "source": [
    "# Lets generate the data profile for the silver dataset\n",
    "generate_data_overview(silver_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
